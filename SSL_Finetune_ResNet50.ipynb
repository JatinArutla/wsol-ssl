{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi2iShNgOQB5"
      },
      "outputs": [],
      "source": [
        "!pip install lightly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hsoaG8G6OVIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Kaggle/data.zip' -d '/content/'"
      ],
      "metadata": {
        "id": "PmWmfYRtOVLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "from cv2 import imread, createCLAHE # read and equalize images\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from pandas.core.common import flatten\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "metadata": {
        "id": "XPmafEgZOVN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "# pytorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# image imports\n",
        "from skimage import io, transform\n",
        "from PIL import Image\n",
        "\n",
        "# general imports\n",
        "import os\n",
        "import time\n",
        "from shutil import copyfile\n",
        "from shutil import rmtree\n",
        "\n",
        "# data science imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv"
      ],
      "metadata": {
        "id": "fwTXuOHAOVQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "import random\n",
        "np.random.seed(25)\n",
        "\n",
        "df = pd.read_csv('/content/Data_Entry_2017.csv')\n",
        "df.drop(['OriginalImage[Width', 'Height]', 'OriginalImagePixelSpacing[x', 'y]', 'Unnamed: 11'], axis=1, inplace=True)\n",
        "num_obs = len(df)\n",
        "# print('Number of observations:',num_obs)\n",
        "\n",
        "my_glob = glob('/content/images*/images/*.png')\n",
        "# print('Number of Observations: ', len(my_glob))\n",
        "\n",
        "full_img_paths = {os.path.basename(x): x for x in my_glob}\n",
        "df['full_path'] = df['Image Index'].map(full_img_paths.get)\n",
        "\n",
        "train_val_list = pd.read_csv('/content/train_val_list.txt', header=None, names = ['image_list'])\n",
        "test_list = pd.read_csv('/content/test_list.txt', header=None, names = ['image_list'])\n",
        "\n",
        "train = df[df['Image Index'].isin(train_val_list['image_list'].values)].reset_index(drop=True)\n",
        "test = df[df['Image Index'].isin(test_list['image_list'].values)].reset_index(drop=True)\n",
        "\n",
        "labels_discard = ['Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Hernia', 'Pleural_Thickening']\n",
        "for i in labels_discard:\n",
        "    train = train[~train['Finding Labels'].str.contains(i)]\n",
        "    test = test[~test['Finding Labels'].str.contains(i)]\n",
        "\n",
        "# train = pd.concat([train[~train['Finding Labels'].str.contains('No Finding')],\n",
        "#                   train[train['Finding Labels'].str.contains('No Finding')].drop_duplicates(subset=['Finding Labels', 'Patient ID', 'View Position'], keep='first')]).sort_values(by='Image Index')\n",
        "\n",
        "def one_hot_enc(df):\n",
        "    df['Finding Labels'] = df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
        "    all_labels = np.unique(list(chain(*df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
        "    for c_label in all_labels:\n",
        "        if len(c_label)>1: # leave out empty labels\n",
        "            df[c_label] = df['Finding Labels'].map(lambda finding: 1 if c_label in finding else 0)\n",
        "    return df\n",
        "\n",
        "train = one_hot_enc(train)\n",
        "test = one_hot_enc(test)\n",
        "\n",
        "train_image_paths = list(flatten(train['full_path'].values))\n",
        "test_image_paths = list(flatten(test['full_path'].values))\n",
        "\n",
        "l = np.unique(train['Patient ID'].values)\n",
        "np.random.shuffle(l)\n",
        "cut = int(np.round(((90/100)*len(l)), decimals=0))\n",
        "train_values = l[:cut]\n",
        "val_values = l[cut:]\n",
        "train_dict = dict.fromkeys(train_values, 'train')\n",
        "train_dict.update(dict.fromkeys(val_values, 'val'))\n",
        "train['fold'] = train['Patient ID'].map(train_dict.get)\n",
        "\n",
        "train = train[['full_path', 'Image Index', 'fold', 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',\n",
        "               'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax']]\n",
        "test['fold'] = 'test'\n",
        "test = test[['full_path', 'Image Index', 'fold', 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',\n",
        "             'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax']]\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "URnFtNqzOVTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "class CreateDataset(Dataset):\n",
        "\n",
        "    def __init__(self, train, fold, transform=None):\n",
        "        self.df = train\n",
        "        self.transform = transform\n",
        "        self.df = self.df[self.df['fold'] == fold]\n",
        "\n",
        "        self.df = self.df.set_index(\"Image Index\")\n",
        "        self.PRED_LABEL = ['Atelectasis',\n",
        "                           'Cardiomegaly',\n",
        "                           'Effusion',\n",
        "                           'Infiltration',\n",
        "                           'Mass',\n",
        "                           'Nodule',\n",
        "                           'Pneumonia',\n",
        "                           'Pneumothorax']\n",
        "        RESULT_PATH = \"results/\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        image = Image.open(self.df.iloc[idx, 0])\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "        label = np.zeros(len(self.PRED_LABEL), dtype=int)\n",
        "        for i in range(0, len(self.PRED_LABEL)):\n",
        "            if(self.df[self.PRED_LABEL[i].strip()].iloc[idx].astype('int') > 0):\n",
        "                label[i] = self.df[self.PRED_LABEL[i].strip()\n",
        "                                  ].iloc[idx].astype('int')\n",
        "\n",
        "#         labels = self.df.iloc[idx, 2:]\n",
        "# #         landmarks = np.array([landmarks])\n",
        "#         labels = torch.Tensor(labels)\n",
        "# #         landmarks = landmarks.astype('float').reshape(-1, 2)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "#         sample = {'image': image, 'landmarks': landmarks}\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "VM3mzR8rOVVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "N_LABELS = 8  # we are predicting 14 labels\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        # transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize(224),\n",
        "        # because resize doesn't always give 224 x 224, this ensures 224 x\n",
        "        # 224\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "}\n",
        "\n",
        "transformed_datasets = {}\n",
        "transformed_datasets['train'] = CreateDataset(train, 'train', transform=data_transforms['train'])\n",
        "transformed_datasets['val'] = CreateDataset(train, 'val', transform=data_transforms['val'])\n",
        "\n",
        "dataloaders = {}\n",
        "dataloaders['train'] = torch.utils.data.DataLoader(\n",
        "    transformed_datasets['train'],\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=8,\n",
        "    pin_memory=True)\n",
        "dataloaders['val'] = torch.utils.data.DataLoader(\n",
        "    transformed_datasets['val'],\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=8,\n",
        "    pin_memory=True)"
      ],
      "metadata": {
        "id": "M0jpJMCXOVYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import sklearn\n",
        "import sklearn.metrics as sklm\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def make_pred_multilabel(model, alignment_network):\n",
        "    \"\"\"\n",
        "    Gives predictions for test fold and calculates AUCs using previously trained model\n",
        "\n",
        "    Args:\n",
        "        data_transforms: torchvision transforms to preprocess raw images; same as validation transforms\n",
        "        model: densenet-121 from torchvision previously fine tuned to training data\n",
        "        PATH_TO_IMAGES: path at which NIH images can be found\n",
        "    Returns:\n",
        "        pred_df: dataframe containing individual predictions and ground truth for each test image\n",
        "        auc_df: dataframe containing aggregate AUCs by train/test tuples\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    BATCH_SIZE = 32\n",
        "    NUM_WORKERS = os.cpu_count()\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            transforms.Resize(224),\n",
        "            # because resize doesn't always give 224 x 224, this ensures 224 x\n",
        "            # 224\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "    }\n",
        "    # calc preds in batches of 16, can reduce if your GPU has less RAM\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    # set model to eval mode; required for proper predictions given use of batchnorm\n",
        "    model.train(False)\n",
        "\n",
        "    # create dataloader\n",
        "    dataset = CreateDataset(test, \"test\", transform=data_transforms['test'])\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=True)\n",
        "    size = len(dataset)\n",
        "\n",
        "    # create empty dfs\n",
        "    pred_df = pd.DataFrame(columns=[\"Image Index\"])\n",
        "    true_df = pd.DataFrame(columns=[\"Image Index\"])\n",
        "\n",
        "    # iterate over dataloader\n",
        "    for i, data in enumerate(dataloader):\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "\n",
        "        true_labels = labels.cpu().data.numpy()\n",
        "        batch_size = true_labels.shape\n",
        "\n",
        "        outputs = model(inputs, alignment_network, batch_masks, lung)\n",
        "        probs = outputs.cpu().data.numpy()\n",
        "\n",
        "        # get predictions and true values for each item in batch\n",
        "        for j in range(0, batch_size[0]):\n",
        "            thisrow = {}\n",
        "            truerow = {}\n",
        "            thisrow[\"Image Index\"] = dataset.df.index[BATCH_SIZE * i + j]\n",
        "            truerow[\"Image Index\"] = dataset.df.index[BATCH_SIZE * i + j]\n",
        "\n",
        "            # iterate over each entry in prediction vector; each corresponds to\n",
        "            # individual label\n",
        "            for k in range(len(dataset.PRED_LABEL)):\n",
        "                thisrow[\"prob_\" + dataset.PRED_LABEL[k]] = probs[j, k]\n",
        "                truerow[dataset.PRED_LABEL[k]] = true_labels[j, k]\n",
        "\n",
        "            pred_df = pred_df.append(thisrow, ignore_index=True)\n",
        "            true_df = true_df.append(truerow, ignore_index=True)\n",
        "\n",
        "#         if(i % 10 == 0):\n",
        "#             print(str(i * BATCH_SIZE))\n",
        "\n",
        "    auc_df = pd.DataFrame(columns=[\"label\", \"auc\"])\n",
        "\n",
        "    # calc AUCs\n",
        "    for column in true_df:\n",
        "        if column not in [\n",
        "            'Atelectasis',\n",
        "            'Cardiomegaly',\n",
        "            'Effusion',\n",
        "            'Infiltration',\n",
        "            'Mass',\n",
        "            'Nodule',\n",
        "            'Pneumonia',\n",
        "            'Pneumothorax']:\n",
        "                    continue\n",
        "        actual = true_df[column]\n",
        "        pred = pred_df[\"prob_\" + column]\n",
        "        thisrow = {}\n",
        "        thisrow['label'] = column\n",
        "        thisrow['auc'] = np.nan\n",
        "#         try:\n",
        "#             thisrow['auc'] = sklm.roc_auc_score(\n",
        "#                 actual.as_matrix().astype(int), pred.as_matrix())\n",
        "        thisrow['auc'] = sklm.roc_auc_score(actual.astype(int), pred)\n",
        "#         except BaseException:\n",
        "#             print(\"can't calculate auc for \" + str(column))\n",
        "        auc_df = auc_df.append(thisrow, ignore_index=True)\n",
        "\n",
        "    pred_df.to_csv(\"results/preds.csv\", index=False)\n",
        "    auc_df.to_csv(\"results/aucs.csv\", index=False)\n",
        "    return pred_df, auc_df, true_df, actual, pred"
      ],
      "metadata": {
        "id": "RKggxxfYOa_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VICReg"
      ],
      "metadata": {
        "id": "sdJ4BOtJOqeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=3,\n",
        "        stride=stride,\n",
        "        padding=dilation,\n",
        "        groups=groups,\n",
        "        bias=False,\n",
        "        dilation=dilation,\n",
        "    )\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    __constants__ = [\"downsample\"]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes,\n",
        "        planes,\n",
        "        stride=1,\n",
        "        downsample=None,\n",
        "        groups=1,\n",
        "        base_width=64,\n",
        "        dilation=1,\n",
        "        norm_layer=None,\n",
        "        last_activation=\"relu\",\n",
        "    ):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    __constants__ = [\"downsample\"]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes,\n",
        "        planes,\n",
        "        stride=1,\n",
        "        downsample=None,\n",
        "        groups=1,\n",
        "        base_width=64,\n",
        "        dilation=1,\n",
        "        norm_layer=None,\n",
        "        last_activation=\"relu\",\n",
        "    ):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.0)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "        if last_activation == \"relu\":\n",
        "            self.last_activation = nn.ReLU(inplace=True)\n",
        "        elif last_activation == \"none\":\n",
        "            self.last_activation = nn.Identity()\n",
        "        elif last_activation == \"sigmoid\":\n",
        "            self.last_activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.last_activation(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        block,\n",
        "        layers,\n",
        "        num_channels=3,\n",
        "        zero_init_residual=False,\n",
        "        groups=1,\n",
        "        widen=1,\n",
        "        width_per_group=64,\n",
        "        replace_stride_with_dilation=None,\n",
        "        norm_layer=None,\n",
        "        last_activation=\"relu\",\n",
        "    ):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "        # self._last_activation = last_activation\n",
        "\n",
        "        self.padding = nn.ConstantPad2d(1, 0.0)\n",
        "\n",
        "        self.inplanes = width_per_group * widen\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\n",
        "                \"replace_stride_with_dilation should be None \"\n",
        "                \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation)\n",
        "            )\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "\n",
        "        # change padding 3 -> 2 compared to original torchvision code because added a padding layer\n",
        "        num_out_filters = width_per_group * widen\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            num_channels,\n",
        "            num_out_filters,\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=2,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.bn1 = norm_layer(num_out_filters)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, num_out_filters, layers[0])\n",
        "        num_out_filters *= 2\n",
        "        self.layer2 = self._make_layer(\n",
        "            block,\n",
        "            num_out_filters,\n",
        "            layers[1],\n",
        "            stride=2,\n",
        "            dilate=replace_stride_with_dilation[0],\n",
        "        )\n",
        "        num_out_filters *= 2\n",
        "        self.layer3 = self._make_layer(\n",
        "            block,\n",
        "            num_out_filters,\n",
        "            layers[2],\n",
        "            stride=2,\n",
        "            dilate=replace_stride_with_dilation[1],\n",
        "        )\n",
        "        num_out_filters *= 2\n",
        "        self.layer4 = self._make_layer(\n",
        "            block,\n",
        "            num_out_filters,\n",
        "            layers[3],\n",
        "            stride=2,\n",
        "            dilate=replace_stride_with_dilation[2],\n",
        "            last_activation=last_activation,\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(\n",
        "        self, block, planes, blocks, stride=1, dilate=False, last_activation=\"relu\"\n",
        "    ):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(\n",
        "                self.inplanes,\n",
        "                planes,\n",
        "                stride,\n",
        "                downsample,\n",
        "                self.groups,\n",
        "                self.base_width,\n",
        "                previous_dilation,\n",
        "                norm_layer,\n",
        "                last_activation=(last_activation if blocks == 1 else \"relu\"),\n",
        "            )\n",
        "        )\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(\n",
        "                block(\n",
        "                    self.inplanes,\n",
        "                    planes,\n",
        "                    groups=self.groups,\n",
        "                    base_width=self.base_width,\n",
        "                    dilation=self.dilation,\n",
        "                    norm_layer=norm_layer,\n",
        "                    last_activation=(last_activation if i == blocks - 1 else \"relu\"),\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.padding(x)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def resnet34(**kwargs):\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs), 512\n",
        "\n",
        "\n",
        "def resnet50(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs), 2048\n",
        "\n",
        "\n",
        "def resnet101(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3], **kwargs), 2048\n",
        "\n",
        "\n",
        "def resnet50x2(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], widen=2, **kwargs), 4096\n",
        "\n",
        "\n",
        "def resnet50x4(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], widen=4, **kwargs), 8192\n",
        "\n",
        "\n",
        "def resnet50x5(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], widen=5, **kwargs), 10240\n",
        "\n",
        "\n",
        "def resnet200x2(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 24, 36, 3], widen=2, **kwargs), 4096"
      ],
      "metadata": {
        "id": "KHPSVVklObFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "## The projection head is the same as the Barlow Twins one\n",
        "from lightly.loss import VICRegLoss\n",
        "\n",
        "## The projection head is the same as the Barlow Twins one\n",
        "from lightly.loss.vicreg_loss import VICRegLoss\n",
        "from lightly.models.modules import BarlowTwinsProjectionHead\n",
        "# from lightly.transforms.vicreg_transform import VICRegTransform\n",
        "\n",
        "\n",
        "class VICReg(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.projection_head = BarlowTwinsProjectionHead(2048, 2048, 2048)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(x)\n",
        "        return z"
      ],
      "metadata": {
        "id": "O0UKxBBlObH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# backbone = resnet50()\n",
        "# backbone = backbone[0]\n",
        "# checkpoint = torch.load('/content/drive/MyDrive/vicreg/resnet50.pth')\n",
        "# backbone.load_state_dict(checkpoint)\n",
        "\n",
        "resnet = torchvision.models.resnet50()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "ssl_model = VICReg(backbone)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "ssl_model.to(device)\n",
        "print('Model initiated')"
      ],
      "metadata": {
        "id": "eHe_71UROuzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('/content/drive/MyDrive/final_random_vicreg/data_aug_vicreg_chestxray_20_withprojectionhead.pth')\n",
        "ssl_model.load_state_dict(checkpoint)\n",
        "backbone = ssl_model.backbone\n",
        "backbone = nn.Sequential(*list(backbone.children()))\n",
        "num_ftrs = 2048\n",
        "backbone.fc = nn.Sequential(\n",
        "    nn.Flatten(), nn.Linear(num_ftrs, 8), nn.Sigmoid())\n",
        "backbone.to(device)\n",
        "print('Model loaded')"
      ],
      "metadata": {
        "id": "R31d2ToeOv9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masks = np.load('/content/drive/MyDrive/thesis_models/final_fixed_aligned_layercam_normalized_masks.npy', allow_pickle=True)\n",
        "for i in range(1, 8):\n",
        "    masks[i] = masks[i].squeeze(0)\n",
        "for i in range(len(masks)):\n",
        "    masks[i] = masks[i].to(torch.float32)\n",
        "\n",
        "# def ptp(t, axis):\n",
        "#   return t.max(axis).values - t.min(axis).values\n",
        "\n",
        "# for i in range(len(masks)):\n",
        "#   mean, std, var = torch.mean(masks[i]), torch.std(masks[i]), torch.var(masks[i])\n",
        "#   min = torch.min\n",
        "#   masks[i]  = (masks[i]-mean)/std\n",
        "# print('-------')\n",
        "# for i in masks:\n",
        "#   mean, std, var = torch.mean(i), torch.std(i), torch.var(i)\n",
        "#   print(mean, std, var)\n",
        "\n",
        "# temp = []\n",
        "# for i in range(7):\n",
        "#     temp1 = [0., 0., 0., 0., 0., 0., 0.]\n",
        "#     temp.append(temp1)\n",
        "# masks[6] = torch.Tensor(temp)\n",
        "\n",
        "l = []\n",
        "for i in masks:\n",
        "    l.append(i)\n",
        "masks = torch.stack(l)\n",
        "\n",
        "batch_masks = []\n",
        "for i in range(32):\n",
        "    batch_masks.append(masks)\n",
        "\n",
        "batch_masks = torch.stack(batch_masks).cuda()\n",
        "batch_masks = batch_masks.to(torch.float32)"
      ],
      "metadata": {
        "id": "Rh9SUO2I67_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lung = np.load('/content/drive/MyDrive/56_lung_mask.npy', allow_pickle=True)\n",
        "\n",
        "lung = lung[0]\n",
        "lung = lung.to(torch.float32)\n",
        "\n",
        "l = []\n",
        "for i in range(256):\n",
        "    l.append(lung)\n",
        "lung = torch.stack(l).cuda()\n",
        "lung = lung.to(torch.float32)"
      ],
      "metadata": {
        "id": "tNIxd9af68Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "centre_lung = np.load('/content/drive/MyDrive/56_center_lung_mask.npy', allow_pickle=True)\n",
        "\n",
        "centre_lung = centre_lung[0]\n",
        "centre_lung = centre_lung.to(torch.float32)\n",
        "\n",
        "l = []\n",
        "for i in range(256):\n",
        "    l.append(centre_lung)\n",
        "centre_lung = torch.stack(l).cuda()\n",
        "centre_lung = centre_lung.to(torch.float32)"
      ],
      "metadata": {
        "id": "P6QlUcBo68GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "import os\n",
        "import torch\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(98)\n",
        "\n",
        "class AlignmentNetwork(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlignmentNetwork, self).__init__()\n",
        "\n",
        "        resnet18 = models.resnet18()\n",
        "        num_ftrs = resnet18.fc.in_features\n",
        "        resnet18.fc = nn.Linear(num_ftrs, 6)\n",
        "\n",
        "        self.model  = resnet18\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        theta = self.model(x)\n",
        "        theta = theta.view(-1, 2, 3).squeeze()\n",
        "\n",
        "        self.grid = F.affine_grid(theta, x.size())\n",
        "        x = F.grid_sample(x, self.grid)\n",
        "#         m = nn.AvgPool2d(16, stride=16)\n",
        "#         x = m(x)\n",
        "#         x = F.interpolate(x, (224,224), mode='bilinear')\n",
        "        return x"
      ],
      "metadata": {
        "id": "0GXcNuDX-4y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the vgg16 is borrowed from the pytorch tutorial\n",
        "# the resent is used to reimplemented and the comparision experiments\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "class ResNet50(torch.nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super(ResNet50, self).__init__()\n",
        "\n",
        "        # resnet50_pretrained = models.resnet50()\n",
        "        # num_ftrs = resnet50_pretrained.fc.in_features\n",
        "        # resnet50_pretrained.fc = nn.Sequential(\n",
        "        #     nn.Linear(num_ftrs, 8), nn.Sigmoid())\n",
        "\n",
        "        resnet50_pretrained = backbone\n",
        "\n",
        "        # resnet50_pretrained.load_state_dict(torch.load('/kaggle/input/models-for-localisation-testing/resnet50_5_chestxray8.pth'))\n",
        "\n",
        "        self.model  = list(resnet50_pretrained.children())\n",
        "\n",
        "        self.noslice1 = self.model[1]\n",
        "        self.noslice2 = self.model[2]\n",
        "        self.noslice3 = self.model[3]\n",
        "        self.noslice4 = self.model[4]\n",
        "\n",
        "        self.slice1 = self.model[5]\n",
        "        self.slice2 = self.model[6]\n",
        "        self.slice3 = self.model[7]\n",
        "        self.slice4 = self.model[8]\n",
        "\n",
        "#         self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n",
        "        self.conv = nn.Sequential(nn.Conv2d(in_channels=2048, out_channels=8, kernel_size=1))\n",
        "                                # nn.ReLU(inplace=True))\n",
        "        self.anothaone = nn.Sequential(nn.Conv2d(in_channels=8, out_channels=8, kernel_size=1))\n",
        "                                # nn.ReLU(inplace=True))\n",
        "        self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)), nn.Sigmoid())\n",
        "        # self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n",
        "        #                         nn.Flatten(),\n",
        "        #                         nn.Linear(2048, 8),\n",
        "        #                         nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x, alignment_network, batch_masks, lung_mask):\n",
        "#         x = x.to(device)\n",
        "        o = x\n",
        "#         for i in range(4):\n",
        "#             o = self.model[i](o)\n",
        "\n",
        "        # alignment_network.eval()\n",
        "        # o = alignment_network(o)\n",
        "        # aligned = o\n",
        "\n",
        "        o = self.noslice1(o)\n",
        "        o = self.noslice2(o)\n",
        "        o = self.noslice3(o)\n",
        "        o = self.noslice4(o)\n",
        "\n",
        "        # o = (o * lung_mask) + o\n",
        "\n",
        "#         anchor = cv.resize()\n",
        "#         o = o*anchor\n",
        "        o = self.slice1(o)\n",
        "        feature1 = o\n",
        "        # o = (o * lung_mask) + o\n",
        "        o = self.slice2(o)\n",
        "        feature2 = o\n",
        "        o = self.slice3(o)\n",
        "        feature3 = o\n",
        "        o = self.slice4(o)\n",
        "        feature4 = o\n",
        "        o = self.conv(o)\n",
        "        final = o\n",
        "        if(o.shape[0] == 32):\n",
        "          o = (o * batch_masks) + o\n",
        "        else:\n",
        "          temp = o.shape[0]\n",
        "          o = (o * batch_masks[:temp]) + o\n",
        "        o = self.anothaone(o)\n",
        "        final2 = o\n",
        "        o = self.fc(o)\n",
        "        final3 = o\n",
        "\n",
        "        return final3"
      ],
      "metadata": {
        "id": "gh1jNeO0dmeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "vicreg_model = ResNet50(backbone)\n",
        "vicreg_model = vicreg_model.to(device)\n",
        "vicreg_model = vicreg_model.type(torch.cuda.FloatTensor)\n",
        "vicreg_model.load_state_dict(torch.load('/content/drive/MyDrive/thesis_models/dataaug_vicreg_noalign_5.pth'))\n",
        "\n",
        "# vicreg_model = ResNet50()\n",
        "# vicreg_model.load_state_dict(torch.load('/content/drive/MyDrive/final_random_init/random_vicreg_oldalign_5.pth'))\n",
        "# vicreg_model = vicreg_model.to(device)\n",
        "# vicreg_model = vicreg_model.type(torch.cuda.FloatTensor)"
      ],
      "metadata": {
        "id": "HjNLjgfRduhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vicreg_model"
      ],
      "metadata": {
        "id": "WVstklkG_D4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723/21\n",
        "# https://www.fast.ai/posts/2018-07-02-adam-weight-decay.html\n",
        "# https://stackoverflow.com/questions/44452571/what-is-the-proper-way-to-weight-decay-for-adam-optimizer\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "gpu_count = torch.cuda.device_count()\n",
        "print(\"Available GPU count:\" + str(gpu_count))\n",
        "\n",
        "\n",
        "def checkpoint(model, best_loss, epoch, LR):\n",
        "    \"\"\"\n",
        "    Saves checkpoint of torchvision model during training.\n",
        "    Args:\n",
        "        model: torchvision model to be saved\n",
        "        best_loss: best val loss achieved so far in training\n",
        "        epoch: current epoch of training\n",
        "        LR: current learning rate in training\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    print('saving')\n",
        "    state = {\n",
        "        'model': model,\n",
        "        'best_loss': best_loss,\n",
        "        'epoch': epoch,\n",
        "        'rng_state': torch.get_rng_state(),\n",
        "        'LR': LR\n",
        "    }\n",
        "\n",
        "    torch.save(state, 'results/checkpoint')\n",
        "\n",
        "def get_loss(output, target, index, device):\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    num_classes = [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "    pos_weight = [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "    batch_weight = True\n",
        "\n",
        "    for num_class in num_classes:\n",
        "        assert num_class == 1\n",
        "    target = target[:, index].view(-1)\n",
        "    output = torch.transpose(output, 0, 1)\n",
        "    pos_weight = torch.from_numpy(\n",
        "        np.array(pos_weight,\n",
        "                 dtype=np.float32)).to(device).type_as(target)\n",
        "\n",
        "    if batch_weight:\n",
        "        if target.sum() == 0:\n",
        "            loss = torch.tensor(0., requires_grad=True).to(device)\n",
        "        else:\n",
        "            weight = (target.size()[0] - target.sum()) / target.sum()\n",
        "            loss = F.binary_cross_entropy_with_logits(\n",
        "                output[index].view(-1), target, pos_weight=weight)\n",
        "    else:\n",
        "        loss = F.binary_cross_entropy_with_logits(\n",
        "            output[index].view(-1), target, pos_weight=pos_weight[index])\n",
        "\n",
        "    label = torch.sigmoid(output[index].view(-1)).ge(0.5).float()\n",
        "    acc = (target == label).float().sum() / len(label)\n",
        "\n",
        "    return (loss, acc)\n",
        "\n",
        "\n",
        "def train_model(\n",
        "        model,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        LR,\n",
        "        num_epochs,\n",
        "        dataloaders,\n",
        "        dataset_sizes,\n",
        "        weight_decay):\n",
        "    \"\"\"\n",
        "    Fine tunes torchvision model to NIH CXR data.\n",
        "    Args:\n",
        "        model: torchvision model to be finetuned (densenet-121 in this case)\n",
        "        criterion: loss criterion (binary cross entropy loss, BCELoss)\n",
        "        optimizer: optimizer to use in training (SGD)\n",
        "        LR: learning rate\n",
        "        num_epochs: continue training up to this many epochs\n",
        "        dataloaders: pytorch train and val dataloaders\n",
        "        dataset_sizes: length of train and val datasets\n",
        "        weight_decay: weight decay parameter we use in SGD with momentum\n",
        "    Returns:\n",
        "        model: trained torchvision model\n",
        "        best_epoch: epoch on which best model val loss was obtained\n",
        "    \"\"\"\n",
        "    since = time.time()\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_loss = 999999\n",
        "    best_epoch = -1\n",
        "    last_train_loss = -1\n",
        "\n",
        "    auc_df_temp = 0\n",
        "    num_tasks = 8\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    alignment_network = AlignmentNetwork()\n",
        "    alignment_network.load_state_dict(torch.load('/content/drive/MyDrive/2feat_no_crop_fixed_pt_alignment_network_5.pth'))\n",
        "    alignment_network = alignment_network.to(device)\n",
        "    alignment_network.eval()\n",
        "\n",
        "    # iterate over epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # set model to train or eval mode based on whether we are in train or\n",
        "        # val; necessary to get correct predictions given batchnorm\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train(True)\n",
        "            else:\n",
        "                model.train(False)\n",
        "\n",
        "            running_loss = 0.0\n",
        "\n",
        "            i = 0\n",
        "            total_done = 0\n",
        "            # iterate over all data in train/val dataloader:\n",
        "            for data in dataloaders[phase]:\n",
        "                i += 1\n",
        "                loss_sum = np.zeros(num_tasks)\n",
        "                acc_sum = np.zeros(num_tasks)\n",
        "                loss = 0\n",
        "                inputs, labels = data\n",
        "                batch_size = inputs.shape[0]\n",
        "                inputs = Variable(inputs.cuda())\n",
        "                labels = Variable(labels.cuda()).float()\n",
        "                outputs = model(inputs, alignment_network, batch_masks, lung)\n",
        "\n",
        "                for t in range(num_tasks):\n",
        "                    loss_t, acc_t = get_loss(outputs, labels, t, device)\n",
        "                    loss += loss_t\n",
        "                    loss_sum[t] += loss_t.item()\n",
        "                    acc_sum[t] += acc_t.item()\n",
        "                # calculate gradient and update parameters in train phase\n",
        "                optimizer.zero_grad()\n",
        "                # loss = criterion(outputs, labels)\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                running_loss += loss.data * batch_size\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "\n",
        "            if phase == 'train':\n",
        "                last_train_loss = epoch_loss\n",
        "\n",
        "            print(phase + ' epoch {}:loss {:.4f} with data size {}'.format(\n",
        "                epoch, epoch_loss, dataset_sizes[phase]))\n",
        "\n",
        "            if (epoch == (num_epochs - 1)):\n",
        "                torch.save(model.state_dict(), f'/content/drive/MyDrive/thesis_models/dataaug_vicreg_layerdmask_noalign_{epoch+6}.pth')\n",
        "\n",
        "            # decay learning rate if no val loss improvement in this epoch\n",
        "\n",
        "#             if phase == 'val' and epoch_loss > best_loss:\n",
        "#                 print(\"decay loss from \" + str(LR) + \" to \" +\n",
        "#                       str(LR / 10) + \" as not seeing improvement in val loss\")\n",
        "#                 LR = LR / 10\n",
        "#                 # create new optimizer with lower learning rate\n",
        "# #                 optimizer = optim.SGD(\n",
        "# #                     filter(\n",
        "# #                         lambda p: p.requires_grad,\n",
        "# #                         model.parameters()),\n",
        "# #                     lr=LR,\n",
        "# #                     momentum=0.9,\n",
        "# #                     weight_decay=weight_decay)\n",
        "#                 optimizer = optim.Adam(model.parameters(),lr=LR, betas=(0.9, 0.999))\n",
        "#                 print(\"created new optimizer with LR \" + str(LR))\n",
        "\n",
        "            # checkpoint model if has best val loss yet\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_epoch = epoch\n",
        "                checkpoint(model, best_loss, epoch, LR)\n",
        "\n",
        "            # log training and validation loss over each epoch\n",
        "            if phase == 'val':\n",
        "                with open(\"results/log_train\", 'a') as logfile:\n",
        "                    logwriter = csv.writer(logfile, delimiter=',')\n",
        "                    if(epoch == 1):\n",
        "                        logwriter.writerow([\"epoch\", \"train_loss\", \"val_loss\"])\n",
        "                    logwriter.writerow([epoch, last_train_loss, epoch_loss])\n",
        "\n",
        "        total_done += batch_size\n",
        "        if(total_done % (100 * batch_size) == 0):\n",
        "            print(\"completed \" + str(total_done) + \" so far in epoch\")\n",
        "\n",
        "        # break if no val loss improvement in 3 epochs\n",
        "#         if ((epoch - best_epoch) >= 3):\n",
        "#             print(\"no improvement in 3 epochs, break\")\n",
        "#             break\n",
        "\n",
        "        pred_df, auc_df, true_df, actual, pred = make_pred_multilabel(model, alignment_network)\n",
        "        if (auc_df_temp > auc_df['auc'].mean()):\n",
        "            auc_df_temp = auc_df['auc'].mean()\n",
        "            print('No increase in AUC. AUC: ', auc_df['auc'].mean())\n",
        "        if (auc_df_temp < auc_df['auc'].mean()):\n",
        "            auc_df_temp = auc_df['auc'].mean()\n",
        "            print('AUC: ', auc_df['auc'].mean())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    # load best model weights to return\n",
        "    checkpoint_best = torch.load('results/checkpoint')\n",
        "    model = checkpoint_best['model']\n",
        "\n",
        "    return model, best_epoch\n",
        "\n",
        "\n",
        "def train_cnn(LR, WEIGHT_DECAY, model):\n",
        "    \"\"\"\n",
        "    Train torchvision model to NIH data given high level hyperparameters.\n",
        "    Args:\n",
        "        PATH_TO_IMAGES: path to NIH images\n",
        "        LR: learning rate\n",
        "        WEIGHT_DECAY: weight decay parameter for SGD\n",
        "    Returns:\n",
        "        preds: torchvision model predictions on test fold with ground truth for comparison\n",
        "        aucs: AUCs for each train,test tuple\n",
        "    \"\"\"\n",
        "    NUM_EPOCHS = 5\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    try:\n",
        "        rmtree('results/')\n",
        "    except BaseException:\n",
        "        pass  # directory doesn't yet exist, no need to clear it\n",
        "    os.makedirs(\"results/\")\n",
        "\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    N_LABELS = 8  # we are predicting 14 labels\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            transforms.Resize(224),\n",
        "            # because resize doesn't always give 224 x 224, this ensures 224 x\n",
        "            # 224\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    transformed_datasets = {}\n",
        "    transformed_datasets['train'] = CreateDataset(train, 'train', transform=data_transforms['train'])\n",
        "    transformed_datasets['val'] = CreateDataset(train, 'val', transform=data_transforms['val'])\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = torch.utils.data.DataLoader(\n",
        "        transformed_datasets['train'],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=8,\n",
        "        pin_memory=True)\n",
        "    dataloaders['val'] = torch.utils.data.DataLoader(\n",
        "        transformed_datasets['val'],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=8,\n",
        "        pin_memory=True)\n",
        "\n",
        "    # please do not attempt to train without GPU as will take excessively long\n",
        "    if not use_gpu:\n",
        "        raise ValueError(\"Error, requires GPU\")\n",
        "\n",
        "    # model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
        "    # num_ftrs = model.fc.in_features\n",
        "    # model.fc = nn.Sequential(\n",
        "    #     nn.Linear(num_ftrs, N_LABELS), nn.Sigmoid())\n",
        "\n",
        "    # put model on GPU\n",
        "    model = model.cuda()\n",
        "\n",
        "#     checkpoint = torch.load('/kaggle/input/chestx-ray/resnet50_5_chestxray8.pth')\n",
        "#     model.load_state_dict(checkpoint)\n",
        "\n",
        "    # define criterion, optimizer for training\n",
        "    criterion = nn.BCELoss()\n",
        "    # criterion = FocalLoss()\n",
        "\n",
        "#     optimizer = optim.Adam(\n",
        "#         filter(\n",
        "#             lambda p: p.requires_grad,\n",
        "#             model.parameters()),\n",
        "#         lr=LR,\n",
        "#         weight_decay=WEIGHT_DECAY)\n",
        "    optimizer = optim.Adam(model.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
        "#     optimizer = optim.SGD(\n",
        "#         filter(\n",
        "#             lambda p: p.requires_grad,\n",
        "#             model.parameters()),\n",
        "#         lr=LR,\n",
        "#         momentum=0.9,\n",
        "#         weight_decay=WEIGHT_DECAY)\n",
        "    dataset_sizes = {x: len(transformed_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "    # train model\n",
        "    model, best_epoch = train_model(model, criterion, optimizer, LR, num_epochs=NUM_EPOCHS,\n",
        "                                    dataloaders=dataloaders, dataset_sizes=dataset_sizes, weight_decay=WEIGHT_DECAY)\n",
        "    print('Finished training')\n",
        "\n",
        "    # get preds and AUCs on test fold\n",
        "\n",
        "    return model, best_epoch"
      ],
      "metadata": {
        "id": "LUEYvpOpgvDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "WEIGHT_DECAY = 0.01\n",
        "LEARNING_RATE = 0.0001\n",
        "model, best_epoch = train_cnn(LEARNING_RATE, WEIGHT_DECAY, vicreg_model)\n",
        "\n",
        "# dataaug_vicreg_layerdmask_noalign_10"
      ],
      "metadata": {
        "id": "SjITCutYgvLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01BAV14Vg3p0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Slvq5sTSg3tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SimSIAM"
      ],
      "metadata": {
        "id": "ydg6GO0OdhDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "from lightly.loss import NegativeCosineSimilarity\n",
        "from lightly.models.modules import SimSiamPredictionHead, SimSiamProjectionHead\n",
        "# from lightly.transforms import SimSiamTransform\n",
        "\n",
        "\n",
        "class SimSiam_Train(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.projection_head = SimSiamProjectionHead(2048, 512, 128)\n",
        "        self.prediction_head = SimSiamPredictionHead(128, 64, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(f)\n",
        "        p = self.prediction_head(z)\n",
        "        z = z.detach()\n",
        "        return z, p"
      ],
      "metadata": {
        "id": "GewQD8mFdukf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates.\n",
        "# All rights reserved.\n",
        "\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class SimSiam(nn.Module):\n",
        "    \"\"\"\n",
        "    Build a SimSiam model.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_encoder, dim=2048, pred_dim=512):\n",
        "        \"\"\"\n",
        "        dim: feature dimension (default: 2048)\n",
        "        pred_dim: hidden dimension of the predictor (default: 512)\n",
        "        \"\"\"\n",
        "        super(SimSiam, self).__init__()\n",
        "\n",
        "        # create the encoder\n",
        "        # num_classes is the output fc dimension, zero-initialize last BNs\n",
        "        self.encoder = base_encoder(num_classes=dim, zero_init_residual=True)\n",
        "\n",
        "        # build a 3-layer projector\n",
        "        prev_dim = self.encoder.fc.weight.shape[1]\n",
        "        self.encoder.fc = nn.Sequential(nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # first layer\n",
        "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # second layer\n",
        "                                        self.encoder.fc,\n",
        "                                        nn.BatchNorm1d(dim, affine=False)) # output layer\n",
        "        self.encoder.fc[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n",
        "\n",
        "        # build a 2-layer predictor\n",
        "        self.predictor = nn.Sequential(nn.Linear(dim, pred_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(pred_dim),\n",
        "                                        nn.ReLU(inplace=True), # hidden layer\n",
        "                                        nn.Linear(pred_dim, dim)) # output layer\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            x1: first views of images\n",
        "            x2: second views of images\n",
        "        Output:\n",
        "            p1, p2, z1, z2: predictors and targets of the network\n",
        "            See Sec. 3 of https://arxiv.org/abs/2011.10566 for detailed notations\n",
        "        \"\"\"\n",
        "\n",
        "        # compute features for one view\n",
        "        z1 = self.encoder(x1) # NxC\n",
        "        z2 = self.encoder(x2) # NxC\n",
        "\n",
        "        p1 = self.predictor(z1) # NxC\n",
        "        p2 = self.predictor(z2) # NxC\n",
        "\n",
        "        return p1, p2, z1.detach(), z2.detach()"
      ],
      "metadata": {
        "id": "h8Nh7LfFdunJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimSiam(\n",
        "    models.__dict__['resnet50'],\n",
        "    2048, 512)\n",
        "\n",
        "model = nn.DataParallel(model)\n",
        "\n",
        "# ckpt = torch.load('/kaggle/input/chestx-ray/fastsiam_2_resnet50_backbonemodel.pth')\n",
        "# backbone.load_state_dict(ckpt['resnet50_parameters'])\n",
        "\n",
        "# checkpoint = torch.load('/content/drive/MyDrive/simsiam/checkpoint_0099.pth.tar')\n",
        "# model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "backbone = nn.Sequential(*list(model.module.children())[:-1])\n",
        "backbone = nn.Sequential(*list(backbone[0].children())[:-1])\n",
        "\n",
        "ssl_model = SimSiam_Train(backbone)\n",
        "\n",
        "# checkpoint = torch.load('/content/pretrained_simsiam_28_withprojectionhead.pth')\n",
        "# model.load_state_dict(checkpoint)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "ssl_model = ssl_model.to(device)\n",
        "print('Model ready for training')"
      ],
      "metadata": {
        "id": "dX7bc5cehd9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('/content/drive/MyDrive/simsiam/simsiam_chestxray_20_withprojectionhead.pth')\n",
        "ssl_model.load_state_dict(checkpoint)\n",
        "backbone = ssl_model.backbone\n",
        "backbone = nn.Sequential(*list(backbone.children()))\n",
        "num_ftrs = 2048\n",
        "backbone.fc = nn.Sequential(\n",
        "    nn.Flatten(), nn.Linear(num_ftrs, 8), nn.Sigmoid())\n",
        "backbone.to(device)\n",
        "print('Model loaded')"
      ],
      "metadata": {
        "id": "UvKY9tNfheAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the vgg16 is borrowed from the pytorch tutorial\n",
        "# the resent is used to reimplemented and the comparision experiments\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "class ResNet50(torch.nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super(ResNet50, self).__init__()\n",
        "\n",
        "        resnet50_pretrained = backbone\n",
        "\n",
        "        # resnet50_pretrained.load_state_dict(torch.load('/kaggle/input/models-for-localisation-testing/resnet50_5_chestxray8.pth'))\n",
        "\n",
        "        self.model  = list(resnet50_pretrained.children())\n",
        "\n",
        "        self.noslice1 = self.model[0]\n",
        "        self.noslice2 = self.model[1]\n",
        "        self.noslice3 = self.model[2]\n",
        "        self.noslice4 = self.model[3]\n",
        "\n",
        "        self.slice1 = self.model[4]\n",
        "        self.slice2 = self.model[5]\n",
        "        self.slice3 = self.model[6]\n",
        "        self.slice4 = self.model[7]\n",
        "\n",
        "#         self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n",
        "        self.conv = nn.Sequential(nn.Conv2d(in_channels=2048, out_channels=8, kernel_size=1))\n",
        "                                # nn.ReLU(inplace=True))\n",
        "        self.anothaone = nn.Sequential(nn.Conv2d(in_channels=8, out_channels=8, kernel_size=1))\n",
        "                                # nn.ReLU(inplace=True))\n",
        "        self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)), nn.Sigmoid())\n",
        "        # self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n",
        "        #                         nn.Flatten(),\n",
        "        #                         nn.Linear(2048, 8),\n",
        "        #                         nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "#         x = x.to(device)\n",
        "        o = x\n",
        "#         for i in range(4):\n",
        "#             o = self.model[i](o)\n",
        "\n",
        "        o = self.noslice1(o)\n",
        "        o = self.noslice2(o)\n",
        "        o = self.noslice3(o)\n",
        "        o = self.noslice4(o)\n",
        "\n",
        "#         anchor = cv.resize()\n",
        "#         o = o*anchor\n",
        "        o = self.slice1(o)\n",
        "        feature1 = o\n",
        "        o = self.slice2(o)\n",
        "        feature2 = o\n",
        "        o = self.slice3(o)\n",
        "        feature3 = o\n",
        "        o = self.slice4(o)\n",
        "        feature4 = o\n",
        "        o = self.conv(o)\n",
        "        final = o\n",
        "        # if(o.shape[0] == 32):\n",
        "        #   o = (o * batch_masks) + o\n",
        "        # else:\n",
        "        #   temp = o.shape[0]\n",
        "        #   o = (o * batch_masks[:temp]) + o\n",
        "        o = self.anothaone(o)\n",
        "        final2 = o\n",
        "        o = self.fc(o)\n",
        "        final3 = o\n",
        "\n",
        "        return final3"
      ],
      "metadata": {
        "id": "NoIwgosVheFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "simsiam_model = ResNet50(backbone)\n",
        "simsiam_model = simsiam_model.to(device)\n",
        "simsiam_model = simsiam_model.type(torch.cuda.FloatTensor)"
      ],
      "metadata": {
        "id": "70a7Ui6LiNnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723/21\n",
        "# https://www.fast.ai/posts/2018-07-02-adam-weight-decay.html\n",
        "# https://stackoverflow.com/questions/44452571/what-is-the-proper-way-to-weight-decay-for-adam-optimizer\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "gpu_count = torch.cuda.device_count()\n",
        "print(\"Available GPU count:\" + str(gpu_count))\n",
        "\n",
        "\n",
        "def checkpoint(model, best_loss, epoch, LR):\n",
        "    \"\"\"\n",
        "    Saves checkpoint of torchvision model during training.\n",
        "    Args:\n",
        "        model: torchvision model to be saved\n",
        "        best_loss: best val loss achieved so far in training\n",
        "        epoch: current epoch of training\n",
        "        LR: current learning rate in training\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    print('saving')\n",
        "    state = {\n",
        "        'model': model,\n",
        "        'best_loss': best_loss,\n",
        "        'epoch': epoch,\n",
        "        'rng_state': torch.get_rng_state(),\n",
        "        'LR': LR\n",
        "    }\n",
        "\n",
        "    torch.save(state, 'results/checkpoint')\n",
        "\n",
        "def get_loss(output, target, index, device):\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    num_classes = [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "    pos_weight = [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "    batch_weight = True\n",
        "\n",
        "    for num_class in num_classes:\n",
        "        assert num_class == 1\n",
        "    target = target[:, index].view(-1)\n",
        "    output = torch.transpose(output, 0, 1)\n",
        "    pos_weight = torch.from_numpy(\n",
        "        np.array(pos_weight,\n",
        "                 dtype=np.float32)).to(device).type_as(target)\n",
        "\n",
        "    if batch_weight:\n",
        "        if target.sum() == 0:\n",
        "            loss = torch.tensor(0., requires_grad=True).to(device)\n",
        "        else:\n",
        "            weight = (target.size()[0] - target.sum()) / target.sum()\n",
        "            loss = F.binary_cross_entropy_with_logits(\n",
        "                output[index].view(-1), target, pos_weight=weight)\n",
        "    else:\n",
        "        loss = F.binary_cross_entropy_with_logits(\n",
        "            output[index].view(-1), target, pos_weight=pos_weight[index])\n",
        "\n",
        "    label = torch.sigmoid(output[index].view(-1)).ge(0.5).float()\n",
        "    acc = (target == label).float().sum() / len(label)\n",
        "\n",
        "    return (loss, acc)\n",
        "\n",
        "\n",
        "def train_model(\n",
        "        model,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        LR,\n",
        "        num_epochs,\n",
        "        dataloaders,\n",
        "        dataset_sizes,\n",
        "        weight_decay):\n",
        "    \"\"\"\n",
        "    Fine tunes torchvision model to NIH CXR data.\n",
        "    Args:\n",
        "        model: torchvision model to be finetuned (densenet-121 in this case)\n",
        "        criterion: loss criterion (binary cross entropy loss, BCELoss)\n",
        "        optimizer: optimizer to use in training (SGD)\n",
        "        LR: learning rate\n",
        "        num_epochs: continue training up to this many epochs\n",
        "        dataloaders: pytorch train and val dataloaders\n",
        "        dataset_sizes: length of train and val datasets\n",
        "        weight_decay: weight decay parameter we use in SGD with momentum\n",
        "    Returns:\n",
        "        model: trained torchvision model\n",
        "        best_epoch: epoch on which best model val loss was obtained\n",
        "    \"\"\"\n",
        "    since = time.time()\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_loss = 999999\n",
        "    best_epoch = -1\n",
        "    last_train_loss = -1\n",
        "\n",
        "    auc_df_temp = 0\n",
        "    num_tasks = 8\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # iterate over epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # set model to train or eval mode based on whether we are in train or\n",
        "        # val; necessary to get correct predictions given batchnorm\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train(True)\n",
        "            else:\n",
        "                model.train(False)\n",
        "\n",
        "            running_loss = 0.0\n",
        "\n",
        "            i = 0\n",
        "            total_done = 0\n",
        "            # iterate over all data in train/val dataloader:\n",
        "            for data in dataloaders[phase]:\n",
        "                i += 1\n",
        "                loss_sum = np.zeros(num_tasks)\n",
        "                acc_sum = np.zeros(num_tasks)\n",
        "                loss = 0\n",
        "                inputs, labels = data\n",
        "                batch_size = inputs.shape[0]\n",
        "                inputs = Variable(inputs.cuda())\n",
        "                labels = Variable(labels.cuda()).float()\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                for t in range(num_tasks):\n",
        "                    loss_t, acc_t = get_loss(outputs, labels, t, device)\n",
        "                    loss += loss_t\n",
        "                    loss_sum[t] += loss_t.item()\n",
        "                    acc_sum[t] += acc_t.item()\n",
        "                # calculate gradient and update parameters in train phase\n",
        "                optimizer.zero_grad()\n",
        "                # loss = criterion(outputs, labels)\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                running_loss += loss.data * batch_size\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "\n",
        "            if phase == 'train':\n",
        "                last_train_loss = epoch_loss\n",
        "\n",
        "            print(phase + ' epoch {}:loss {:.4f} with data size {}'.format(\n",
        "                epoch, epoch_loss, dataset_sizes[phase]))\n",
        "\n",
        "            torch.save(model.state_dict(), f'/content/drive/MyDrive/final_ssl/simsiam_resnet50_{epoch+1}.pth')\n",
        "\n",
        "            # decay learning rate if no val loss improvement in this epoch\n",
        "\n",
        "#             if phase == 'val' and epoch_loss > best_loss:\n",
        "#                 print(\"decay loss from \" + str(LR) + \" to \" +\n",
        "#                       str(LR / 10) + \" as not seeing improvement in val loss\")\n",
        "#                 LR = LR / 10\n",
        "#                 # create new optimizer with lower learning rate\n",
        "# #                 optimizer = optim.SGD(\n",
        "# #                     filter(\n",
        "# #                         lambda p: p.requires_grad,\n",
        "# #                         model.parameters()),\n",
        "# #                     lr=LR,\n",
        "# #                     momentum=0.9,\n",
        "# #                     weight_decay=weight_decay)\n",
        "#                 optimizer = optim.Adam(model.parameters(),lr=LR, betas=(0.9, 0.999))\n",
        "#                 print(\"created new optimizer with LR \" + str(LR))\n",
        "\n",
        "            # checkpoint model if has best val loss yet\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_epoch = epoch\n",
        "                checkpoint(model, best_loss, epoch, LR)\n",
        "\n",
        "            # log training and validation loss over each epoch\n",
        "            if phase == 'val':\n",
        "                with open(\"results/log_train\", 'a') as logfile:\n",
        "                    logwriter = csv.writer(logfile, delimiter=',')\n",
        "                    if(epoch == 1):\n",
        "                        logwriter.writerow([\"epoch\", \"train_loss\", \"val_loss\"])\n",
        "                    logwriter.writerow([epoch, last_train_loss, epoch_loss])\n",
        "\n",
        "        total_done += batch_size\n",
        "        if(total_done % (100 * batch_size) == 0):\n",
        "            print(\"completed \" + str(total_done) + \" so far in epoch\")\n",
        "\n",
        "        # break if no val loss improvement in 3 epochs\n",
        "#         if ((epoch - best_epoch) >= 3):\n",
        "#             print(\"no improvement in 3 epochs, break\")\n",
        "#             break\n",
        "\n",
        "        pred_df, auc_df, true_df, actual, pred = make_pred_multilabel(model)\n",
        "        if (auc_df_temp > auc_df['auc'].mean()):\n",
        "            auc_df_temp = auc_df['auc'].mean()\n",
        "            print('No increase in AUC. AUC: ', auc_df['auc'].mean())\n",
        "        if (auc_df_temp < auc_df['auc'].mean()):\n",
        "            auc_df_temp = auc_df['auc'].mean()\n",
        "            print('AUC: ', auc_df['auc'].mean())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    # load best model weights to return\n",
        "    checkpoint_best = torch.load('results/checkpoint')\n",
        "    model = checkpoint_best['model']\n",
        "\n",
        "    return model, best_epoch\n",
        "\n",
        "\n",
        "def train_cnn(LR, WEIGHT_DECAY, model):\n",
        "    \"\"\"\n",
        "    Train torchvision model to NIH data given high level hyperparameters.\n",
        "    Args:\n",
        "        PATH_TO_IMAGES: path to NIH images\n",
        "        LR: learning rate\n",
        "        WEIGHT_DECAY: weight decay parameter for SGD\n",
        "    Returns:\n",
        "        preds: torchvision model predictions on test fold with ground truth for comparison\n",
        "        aucs: AUCs for each train,test tuple\n",
        "    \"\"\"\n",
        "    NUM_EPOCHS = 7\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    try:\n",
        "        rmtree('results/')\n",
        "    except BaseException:\n",
        "        pass  # directory doesn't yet exist, no need to clear it\n",
        "    os.makedirs(\"results/\")\n",
        "\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    N_LABELS = 8  # we are predicting 14 labels\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            transforms.Resize(224),\n",
        "            # because resize doesn't always give 224 x 224, this ensures 224 x\n",
        "            # 224\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    transformed_datasets = {}\n",
        "    transformed_datasets['train'] = CreateDataset(train, 'train', transform=data_transforms['train'])\n",
        "    transformed_datasets['val'] = CreateDataset(train, 'val', transform=data_transforms['val'])\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = torch.utils.data.DataLoader(\n",
        "        transformed_datasets['train'],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=8,\n",
        "        pin_memory=True)\n",
        "    dataloaders['val'] = torch.utils.data.DataLoader(\n",
        "        transformed_datasets['val'],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=8,\n",
        "        pin_memory=True)\n",
        "\n",
        "    # please do not attempt to train without GPU as will take excessively long\n",
        "    if not use_gpu:\n",
        "        raise ValueError(\"Error, requires GPU\")\n",
        "\n",
        "    # model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
        "    # num_ftrs = model.fc.in_features\n",
        "    # model.fc = nn.Sequential(\n",
        "    #     nn.Linear(num_ftrs, N_LABELS), nn.Sigmoid())\n",
        "\n",
        "    # put model on GPU\n",
        "    model = model.cuda()\n",
        "\n",
        "#     checkpoint = torch.load('/kaggle/input/chestx-ray/resnet50_5_chestxray8.pth')\n",
        "#     model.load_state_dict(checkpoint)\n",
        "\n",
        "    # define criterion, optimizer for training\n",
        "    criterion = nn.BCELoss()\n",
        "    # criterion = FocalLoss()\n",
        "\n",
        "#     optimizer = optim.Adam(\n",
        "#         filter(\n",
        "#             lambda p: p.requires_grad,\n",
        "#             model.parameters()),\n",
        "#         lr=LR,\n",
        "#         weight_decay=WEIGHT_DECAY)\n",
        "    optimizer = optim.Adam(model.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
        "#     optimizer = optim.SGD(\n",
        "#         filter(\n",
        "#             lambda p: p.requires_grad,\n",
        "#             model.parameters()),\n",
        "#         lr=LR,\n",
        "#         momentum=0.9,\n",
        "#         weight_decay=WEIGHT_DECAY)\n",
        "    dataset_sizes = {x: len(transformed_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "    # train model\n",
        "    model, best_epoch = train_model(model, criterion, optimizer, LR, num_epochs=NUM_EPOCHS,\n",
        "                                    dataloaders=dataloaders, dataset_sizes=dataset_sizes, weight_decay=WEIGHT_DECAY)\n",
        "    print('Finished training')\n",
        "\n",
        "    # get preds and AUCs on test fold\n",
        "\n",
        "    return model, best_epoch"
      ],
      "metadata": {
        "id": "5trtgpomiNrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "WEIGHT_DECAY = 0.01\n",
        "LEARNING_RATE = 0.0001\n",
        "model, best_epoch = train_cnn(LEARNING_RATE, WEIGHT_DECAY, simsiam_model)"
      ],
      "metadata": {
        "id": "DFy4jrh7iN1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gmpanYp0iN4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gS9atpm5681T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Barlow"
      ],
      "metadata": {
        "id": "JnBVy2YC69fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BarlowTwins(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.projection_head = BarlowTwinsProjectionHead(2048, 2048, 2048)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(x)\n",
        "        return z"
      ],
      "metadata": {
        "id": "F_M8ZLBM6-_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = torchvision.models.resnet50()\n",
        "# backbone = nn.DataParallel(backbone)\n",
        "# checkpoint = torch.load('/content/drive/MyDrive/barlow/resnet50.pth')\n",
        "# backbone.load_state_dict(checkpoint, strict=False)\n",
        "backbone = nn.Sequential(*list(backbone.children())[:-1])"
      ],
      "metadata": {
        "id": "P7P0xEZb7GdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ssl_model = BarlowTwins(backbone)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "ssl_model.to(device)\n",
        "\n",
        "checkpoint = torch.load('/content/drive/MyDrive/barlow/barlow_chestxray_20_withprojectionhead.pth')\n",
        "ssl_model.load_state_dict(checkpoint)"
      ],
      "metadata": {
        "id": "4jbXMPAI7Ggh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = ssl_model.backbone\n",
        "backbone = nn.Sequential(*list(backbone.children()))\n",
        "num_ftrs = 2048\n",
        "backbone.fc = nn.Sequential(\n",
        "    nn.Flatten(), nn.Linear(num_ftrs, 8), nn.Sigmoid())\n",
        "backbone.to(device)\n",
        "print('Model loaded')"
      ],
      "metadata": {
        "id": "_JJtwz0x7Gjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the vgg16 is borrowed from the pytorch tutorial\n",
        "# the resent is used to reimplemented and the comparision experiments\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "class ResNet50(torch.nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super(ResNet50, self).__init__()\n",
        "\n",
        "        resnet50_pretrained = backbone\n",
        "\n",
        "        # resnet50_pretrained.load_state_dict(torch.load('/kaggle/input/models-for-localisation-testing/resnet50_5_chestxray8.pth'))\n",
        "\n",
        "        self.model  = list(resnet50_pretrained.children())\n",
        "\n",
        "        self.noslice1 = self.model[0]\n",
        "        self.noslice2 = self.model[1]\n",
        "        self.noslice3 = self.model[2]\n",
        "        self.noslice4 = self.model[3]\n",
        "\n",
        "        self.slice1 = self.model[4]\n",
        "        self.slice2 = self.model[5]\n",
        "        self.slice3 = self.model[6]\n",
        "        self.slice4 = self.model[7]\n",
        "\n",
        "#         self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n",
        "        self.conv = nn.Sequential(nn.Conv2d(in_channels=2048, out_channels=8, kernel_size=1))\n",
        "                                # nn.ReLU(inplace=True))\n",
        "        self.anothaone = nn.Sequential(nn.Conv2d(in_channels=8, out_channels=8, kernel_size=1))\n",
        "                                # nn.ReLU(inplace=True))\n",
        "        self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)), nn.Sigmoid())\n",
        "        # self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n",
        "        #                         nn.Flatten(),\n",
        "        #                         nn.Linear(2048, 8),\n",
        "        #                         nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "#         x = x.to(device)\n",
        "        o = x\n",
        "#         for i in range(4):\n",
        "#             o = self.model[i](o)\n",
        "\n",
        "        o = self.noslice1(o)\n",
        "        o = self.noslice2(o)\n",
        "        o = self.noslice3(o)\n",
        "        o = self.noslice4(o)\n",
        "\n",
        "#         anchor = cv.resize()\n",
        "#         o = o*anchor\n",
        "        o = self.slice1(o)\n",
        "        feature1 = o\n",
        "        o = self.slice2(o)\n",
        "        feature2 = o\n",
        "        o = self.slice3(o)\n",
        "        feature3 = o\n",
        "        o = self.slice4(o)\n",
        "        feature4 = o\n",
        "        o = self.conv(o)\n",
        "        final = o\n",
        "        # if(o.shape[0] == 32):\n",
        "        #   o = (o * batch_masks) + o\n",
        "        # else:\n",
        "        #   temp = o.shape[0]\n",
        "        #   o = (o * batch_masks[:temp]) + o\n",
        "        o = self.anothaone(o)\n",
        "        final2 = o\n",
        "        o = self.fc(o)\n",
        "        final3 = o\n",
        "\n",
        "        return final3"
      ],
      "metadata": {
        "id": "cAINYUtQ7GoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "barlow_model = ResNet50(backbone)\n",
        "barlow_model = barlow_model.to(device)\n",
        "barlow_model = barlow_model.type(torch.cuda.FloatTensor)"
      ],
      "metadata": {
        "id": "P42TDexW709U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723/21\n",
        "# https://www.fast.ai/posts/2018-07-02-adam-weight-decay.html\n",
        "# https://stackoverflow.com/questions/44452571/what-is-the-proper-way-to-weight-decay-for-adam-optimizer\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "gpu_count = torch.cuda.device_count()\n",
        "print(\"Available GPU count:\" + str(gpu_count))\n",
        "\n",
        "\n",
        "def checkpoint(model, best_loss, epoch, LR):\n",
        "    \"\"\"\n",
        "    Saves checkpoint of torchvision model during training.\n",
        "    Args:\n",
        "        model: torchvision model to be saved\n",
        "        best_loss: best val loss achieved so far in training\n",
        "        epoch: current epoch of training\n",
        "        LR: current learning rate in training\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    print('saving')\n",
        "    state = {\n",
        "        'model': model,\n",
        "        'best_loss': best_loss,\n",
        "        'epoch': epoch,\n",
        "        'rng_state': torch.get_rng_state(),\n",
        "        'LR': LR\n",
        "    }\n",
        "\n",
        "    torch.save(state, 'results/checkpoint')\n",
        "\n",
        "def get_loss(output, target, index, device):\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    num_classes = [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "    pos_weight = [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "    batch_weight = True\n",
        "\n",
        "    for num_class in num_classes:\n",
        "        assert num_class == 1\n",
        "    target = target[:, index].view(-1)\n",
        "    output = torch.transpose(output, 0, 1)\n",
        "    pos_weight = torch.from_numpy(\n",
        "        np.array(pos_weight,\n",
        "                 dtype=np.float32)).to(device).type_as(target)\n",
        "\n",
        "    if batch_weight:\n",
        "        if target.sum() == 0:\n",
        "            loss = torch.tensor(0., requires_grad=True).to(device)\n",
        "        else:\n",
        "            weight = (target.size()[0] - target.sum()) / target.sum()\n",
        "            loss = F.binary_cross_entropy_with_logits(\n",
        "                output[index].view(-1), target, pos_weight=weight)\n",
        "    else:\n",
        "        loss = F.binary_cross_entropy_with_logits(\n",
        "            output[index].view(-1), target, pos_weight=pos_weight[index])\n",
        "\n",
        "    label = torch.sigmoid(output[index].view(-1)).ge(0.5).float()\n",
        "    acc = (target == label).float().sum() / len(label)\n",
        "\n",
        "    return (loss, acc)\n",
        "\n",
        "\n",
        "def train_model(\n",
        "        model,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        LR,\n",
        "        num_epochs,\n",
        "        dataloaders,\n",
        "        dataset_sizes,\n",
        "        weight_decay):\n",
        "    \"\"\"\n",
        "    Fine tunes torchvision model to NIH CXR data.\n",
        "    Args:\n",
        "        model: torchvision model to be finetuned (densenet-121 in this case)\n",
        "        criterion: loss criterion (binary cross entropy loss, BCELoss)\n",
        "        optimizer: optimizer to use in training (SGD)\n",
        "        LR: learning rate\n",
        "        num_epochs: continue training up to this many epochs\n",
        "        dataloaders: pytorch train and val dataloaders\n",
        "        dataset_sizes: length of train and val datasets\n",
        "        weight_decay: weight decay parameter we use in SGD with momentum\n",
        "    Returns:\n",
        "        model: trained torchvision model\n",
        "        best_epoch: epoch on which best model val loss was obtained\n",
        "    \"\"\"\n",
        "    since = time.time()\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_loss = 999999\n",
        "    best_epoch = -1\n",
        "    last_train_loss = -1\n",
        "\n",
        "    auc_df_temp = 0\n",
        "    num_tasks = 8\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # iterate over epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # set model to train or eval mode based on whether we are in train or\n",
        "        # val; necessary to get correct predictions given batchnorm\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train(True)\n",
        "            else:\n",
        "                model.train(False)\n",
        "\n",
        "            running_loss = 0.0\n",
        "\n",
        "            i = 0\n",
        "            total_done = 0\n",
        "            # iterate over all data in train/val dataloader:\n",
        "            for data in dataloaders[phase]:\n",
        "                i += 1\n",
        "                loss_sum = np.zeros(num_tasks)\n",
        "                acc_sum = np.zeros(num_tasks)\n",
        "                loss = 0\n",
        "                inputs, labels = data\n",
        "                batch_size = inputs.shape[0]\n",
        "                inputs = Variable(inputs.cuda())\n",
        "                labels = Variable(labels.cuda()).float()\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                for t in range(num_tasks):\n",
        "                    loss_t, acc_t = get_loss(outputs, labels, t, device)\n",
        "                    loss += loss_t\n",
        "                    loss_sum[t] += loss_t.item()\n",
        "                    acc_sum[t] += acc_t.item()\n",
        "                # calculate gradient and update parameters in train phase\n",
        "                optimizer.zero_grad()\n",
        "                # loss = criterion(outputs, labels)\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                running_loss += loss.data * batch_size\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "\n",
        "            if phase == 'train':\n",
        "                last_train_loss = epoch_loss\n",
        "\n",
        "            print(phase + ' epoch {}:loss {:.4f} with data size {}'.format(\n",
        "                epoch, epoch_loss, dataset_sizes[phase]))\n",
        "\n",
        "            torch.save(model.state_dict(), f'/content/drive/MyDrive/final_ssl/barlow_resnet50_{epoch+1}.pth')\n",
        "\n",
        "            # decay learning rate if no val loss improvement in this epoch\n",
        "\n",
        "#             if phase == 'val' and epoch_loss > best_loss:\n",
        "#                 print(\"decay loss from \" + str(LR) + \" to \" +\n",
        "#                       str(LR / 10) + \" as not seeing improvement in val loss\")\n",
        "#                 LR = LR / 10\n",
        "#                 # create new optimizer with lower learning rate\n",
        "# #                 optimizer = optim.SGD(\n",
        "# #                     filter(\n",
        "# #                         lambda p: p.requires_grad,\n",
        "# #                         model.parameters()),\n",
        "# #                     lr=LR,\n",
        "# #                     momentum=0.9,\n",
        "# #                     weight_decay=weight_decay)\n",
        "#                 optimizer = optim.Adam(model.parameters(),lr=LR, betas=(0.9, 0.999))\n",
        "#                 print(\"created new optimizer with LR \" + str(LR))\n",
        "\n",
        "            # checkpoint model if has best val loss yet\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_epoch = epoch\n",
        "                checkpoint(model, best_loss, epoch, LR)\n",
        "\n",
        "            # log training and validation loss over each epoch\n",
        "            if phase == 'val':\n",
        "                with open(\"results/log_train\", 'a') as logfile:\n",
        "                    logwriter = csv.writer(logfile, delimiter=',')\n",
        "                    if(epoch == 1):\n",
        "                        logwriter.writerow([\"epoch\", \"train_loss\", \"val_loss\"])\n",
        "                    logwriter.writerow([epoch, last_train_loss, epoch_loss])\n",
        "\n",
        "        total_done += batch_size\n",
        "        if(total_done % (100 * batch_size) == 0):\n",
        "            print(\"completed \" + str(total_done) + \" so far in epoch\")\n",
        "\n",
        "        # break if no val loss improvement in 3 epochs\n",
        "#         if ((epoch - best_epoch) >= 3):\n",
        "#             print(\"no improvement in 3 epochs, break\")\n",
        "#             break\n",
        "\n",
        "        pred_df, auc_df, true_df, actual, pred = make_pred_multilabel(model)\n",
        "        if (auc_df_temp > auc_df['auc'].mean()):\n",
        "            auc_df_temp = auc_df['auc'].mean()\n",
        "            print('No increase in AUC. AUC: ', auc_df['auc'].mean())\n",
        "        if (auc_df_temp < auc_df['auc'].mean()):\n",
        "            auc_df_temp = auc_df['auc'].mean()\n",
        "            print('AUC: ', auc_df['auc'].mean())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    # load best model weights to return\n",
        "    checkpoint_best = torch.load('results/checkpoint')\n",
        "    model = checkpoint_best['model']\n",
        "\n",
        "    return model, best_epoch\n",
        "\n",
        "\n",
        "def train_cnn(LR, WEIGHT_DECAY, model):\n",
        "    \"\"\"\n",
        "    Train torchvision model to NIH data given high level hyperparameters.\n",
        "    Args:\n",
        "        PATH_TO_IMAGES: path to NIH images\n",
        "        LR: learning rate\n",
        "        WEIGHT_DECAY: weight decay parameter for SGD\n",
        "    Returns:\n",
        "        preds: torchvision model predictions on test fold with ground truth for comparison\n",
        "        aucs: AUCs for each train,test tuple\n",
        "    \"\"\"\n",
        "    NUM_EPOCHS = 7\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    try:\n",
        "        rmtree('results/')\n",
        "    except BaseException:\n",
        "        pass  # directory doesn't yet exist, no need to clear it\n",
        "    os.makedirs(\"results/\")\n",
        "\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    N_LABELS = 8  # we are predicting 14 labels\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            transforms.Resize(224),\n",
        "            # because resize doesn't always give 224 x 224, this ensures 224 x\n",
        "            # 224\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    transformed_datasets = {}\n",
        "    transformed_datasets['train'] = CreateDataset(train, 'train', transform=data_transforms['train'])\n",
        "    transformed_datasets['val'] = CreateDataset(train, 'val', transform=data_transforms['val'])\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = torch.utils.data.DataLoader(\n",
        "        transformed_datasets['train'],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=8,\n",
        "        pin_memory=True)\n",
        "    dataloaders['val'] = torch.utils.data.DataLoader(\n",
        "        transformed_datasets['val'],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=8,\n",
        "        pin_memory=True)\n",
        "\n",
        "    # please do not attempt to train without GPU as will take excessively long\n",
        "    if not use_gpu:\n",
        "        raise ValueError(\"Error, requires GPU\")\n",
        "\n",
        "    # model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
        "    # num_ftrs = model.fc.in_features\n",
        "    # model.fc = nn.Sequential(\n",
        "    #     nn.Linear(num_ftrs, N_LABELS), nn.Sigmoid())\n",
        "\n",
        "    # put model on GPU\n",
        "    model = model.cuda()\n",
        "\n",
        "#     checkpoint = torch.load('/kaggle/input/chestx-ray/resnet50_5_chestxray8.pth')\n",
        "#     model.load_state_dict(checkpoint)\n",
        "\n",
        "    # define criterion, optimizer for training\n",
        "    criterion = nn.BCELoss()\n",
        "    # criterion = FocalLoss()\n",
        "\n",
        "#     optimizer = optim.Adam(\n",
        "#         filter(\n",
        "#             lambda p: p.requires_grad,\n",
        "#             model.parameters()),\n",
        "#         lr=LR,\n",
        "#         weight_decay=WEIGHT_DECAY)\n",
        "    optimizer = optim.Adam(model.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
        "#     optimizer = optim.SGD(\n",
        "#         filter(\n",
        "#             lambda p: p.requires_grad,\n",
        "#             model.parameters()),\n",
        "#         lr=LR,\n",
        "#         momentum=0.9,\n",
        "#         weight_decay=WEIGHT_DECAY)\n",
        "    dataset_sizes = {x: len(transformed_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "    # train model\n",
        "    model, best_epoch = train_model(model, criterion, optimizer, LR, num_epochs=NUM_EPOCHS,\n",
        "                                    dataloaders=dataloaders, dataset_sizes=dataset_sizes, weight_decay=WEIGHT_DECAY)\n",
        "    print('Finished training')\n",
        "\n",
        "    # get preds and AUCs on test fold\n",
        "\n",
        "    return model, best_epoch"
      ],
      "metadata": {
        "id": "1oTOHTir71CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "WEIGHT_DECAY = 0.01\n",
        "LEARNING_RATE = 0.0001\n",
        "model, best_epoch = train_cnn(LEARNING_RATE, WEIGHT_DECAY, barlow_model)"
      ],
      "metadata": {
        "id": "TFnRJ1LT71Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uaxgyk9p8J18"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}