{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVt-V1d4R_5N"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Kaggle/data.zip' -d '/content/'"
      ],
      "metadata": {
        "id": "WWrD88tqSNzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "from cv2 import imread, createCLAHE # read and equalize images\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from pandas.core.common import flatten\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "metadata": {
        "id": "WkeU03roSN2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "# pytorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# image imports\n",
        "from skimage import io, transform\n",
        "from PIL import Image\n",
        "\n",
        "# general imports\n",
        "import os\n",
        "import time\n",
        "from shutil import copyfile\n",
        "from shutil import rmtree\n",
        "\n",
        "# data science imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv"
      ],
      "metadata": {
        "id": "Mtt-9mHmSN5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightly"
      ],
      "metadata": {
        "id": "y5kEu5PmSN7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "import random\n",
        "np.random.seed(25)\n",
        "\n",
        "df = pd.read_csv('/content/Data_Entry_2017.csv')\n",
        "df.drop(['OriginalImage[Width', 'Height]', 'OriginalImagePixelSpacing[x', 'y]', 'Unnamed: 11'], axis=1, inplace=True)\n",
        "num_obs = len(df)\n",
        "# print('Number of observations:',num_obs)\n",
        "\n",
        "my_glob = glob('/content/images*/images/*.png')\n",
        "# print('Number of Observations: ', len(my_glob))\n",
        "\n",
        "full_img_paths = {os.path.basename(x): x for x in my_glob}\n",
        "df['full_path'] = df['Image Index'].map(full_img_paths.get)\n",
        "\n",
        "train_val_list = pd.read_csv('/content/train_val_list.txt', header=None, names = ['image_list'])\n",
        "test_list = pd.read_csv('/content/test_list.txt', header=None, names = ['image_list'])\n",
        "\n",
        "train = df[df['Image Index'].isin(train_val_list['image_list'].values)].reset_index(drop=True)\n",
        "test = df[df['Image Index'].isin(test_list['image_list'].values)].reset_index(drop=True)\n",
        "\n",
        "labels_discard = ['Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Hernia', 'Pleural_Thickening']\n",
        "for i in labels_discard:\n",
        "    train = train[~train['Finding Labels'].str.contains(i)]\n",
        "    test = test[~test['Finding Labels'].str.contains(i)]\n",
        "\n",
        "# train = pd.concat([train[~train['Finding Labels'].str.contains('No Finding')],\n",
        "#                   train[train['Finding Labels'].str.contains('No Finding')].drop_duplicates(subset=['Finding Labels', 'Patient ID', 'View Position'], keep='first')]).sort_values(by='Image Index')\n",
        "\n",
        "def one_hot_enc(df):\n",
        "    df['Finding Labels'] = df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
        "    all_labels = np.unique(list(chain(*df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
        "    for c_label in all_labels:\n",
        "        if len(c_label)>1: # leave out empty labels\n",
        "            df[c_label] = df['Finding Labels'].map(lambda finding: 1 if c_label in finding else 0)\n",
        "    return df\n",
        "\n",
        "train = one_hot_enc(train)\n",
        "test = one_hot_enc(test)\n",
        "\n",
        "train_image_paths = list(flatten(train['full_path'].values))\n",
        "test_image_paths = list(flatten(test['full_path'].values))\n",
        "\n",
        "l = np.unique(train['Patient ID'].values)\n",
        "np.random.shuffle(l)\n",
        "cut = int(np.round(((90/100)*len(l)), decimals=0))\n",
        "train_values = l[:cut]\n",
        "val_values = l[cut:]\n",
        "train_dict = dict.fromkeys(train_values, 'train')\n",
        "train_dict.update(dict.fromkeys(val_values, 'val'))\n",
        "train['fold'] = train['Patient ID'].map(train_dict.get)\n",
        "\n",
        "train = train[['full_path', 'Image Index', 'fold', 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',\n",
        "               'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax']]\n",
        "test['fold'] = 'test'\n",
        "test = test[['full_path', 'Image Index', 'fold', 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',\n",
        "             'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax']]\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "hebggjQKSN-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import (\n",
        "    Dataset,\n",
        "    DataLoader,\n",
        ")\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import (\n",
        "    RandomResizedCrop,\n",
        "    RandomHorizontalFlip,\n",
        "    ColorJitter,\n",
        "    RandomGrayscale,\n",
        "    RandomApply,\n",
        "    Compose,\n",
        "    GaussianBlur,\n",
        "    ToTensor,\n",
        ")\n",
        "import torchvision.models as models\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "1jmEibppSOCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image as img\n",
        "\n",
        "class CreateDataset(Dataset):\n",
        "\n",
        "    def __init__(self, train, fold, transform):\n",
        "        self.df = train\n",
        "        self.transform = transform\n",
        "        self.df = self.df[self.df['fold'] == fold]\n",
        "\n",
        "        self.df = self.df.set_index(\"Image Index\")\n",
        "        self.PRED_LABEL = ['Atelectasis',\n",
        "                           'Cardiomegaly',\n",
        "                           'Effusion',\n",
        "                           'Infiltration',\n",
        "                           'Mass',\n",
        "                           'Nodule',\n",
        "                           'Pneumonia',\n",
        "                           'Pneumothorax']\n",
        "        RESULT_PATH = \"results/\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        image = img.open(self.df.iloc[idx, 0])\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "        label = np.zeros(len(self.PRED_LABEL), dtype=int)\n",
        "        for i in range(0, len(self.PRED_LABEL)):\n",
        "            if(self.df[self.PRED_LABEL[i].strip()].iloc[idx].astype('int') > 0):\n",
        "                label[i] = self.df[self.PRED_LABEL[i].strip()\n",
        "                                  ].iloc[idx].astype('int')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image"
      ],
      "metadata": {
        "id": "EEQwILwvSOE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "from lightly.loss import NegativeCosineSimilarity\n",
        "from lightly.models.modules import SimSiamPredictionHead, SimSiamProjectionHead\n",
        "from lightly.transforms import FastSiamTransform"
      ],
      "metadata": {
        "id": "8d_1fZ91SOHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Tuple, Union\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from PIL.Image import Image\n",
        "from torch import Tensor\n",
        "\n",
        "from lightly.transforms.gaussian_blur import GaussianBlur\n",
        "from lightly.transforms.multi_view_transform import MultiViewTransform\n",
        "from lightly.transforms.rotation import random_rotation_transform\n",
        "from lightly.transforms.solarize import RandomSolarization\n",
        "from lightly.transforms.utils import IMAGENET_NORMALIZE\n",
        "\n",
        "\n",
        "class VICRegTransform(MultiViewTransform):\n",
        "    \"\"\"Implements the transformations for VICReg.\n",
        "\n",
        "    Input to this transform:\n",
        "        PIL Image or Tensor.\n",
        "\n",
        "    Output of this transform:\n",
        "        List of Tensor of length 2.\n",
        "\n",
        "    Applies the following augmentations by default:\n",
        "        - Random resized crop\n",
        "        - Random horizontal flip\n",
        "        - Color jitter\n",
        "        - Random gray scale\n",
        "        - Random solarization\n",
        "        - Gaussian blur\n",
        "        - ImageNet normalization\n",
        "\n",
        "    Similar to SimCLR transform but with extra solarization.\n",
        "\n",
        "    Attributes:\n",
        "        input_size:\n",
        "            Size of the input image in pixels.\n",
        "        cj_prob:\n",
        "            Probability that color jitter is applied.\n",
        "        cj_strength:\n",
        "            Strength of the color jitter. `cj_bright`, `cj_contrast`, `cj_sat`, and\n",
        "            `cj_hue` are multiplied by this value.\n",
        "        cj_bright:\n",
        "            How much to jitter brightness.\n",
        "        cj_contrast:\n",
        "            How much to jitter constrast.\n",
        "        cj_sat:\n",
        "            How much to jitter saturation.\n",
        "        cj_hue:\n",
        "            How much to jitter hue.\n",
        "        min_scale:\n",
        "            Minimum size of the randomized crop relative to the input_size.\n",
        "        random_gray_scale:\n",
        "            Probability of conversion to grayscale.\n",
        "        solarize_prob:\n",
        "            Probability of solarization.\n",
        "        gaussian_blur:\n",
        "            Probability of Gaussian blur.\n",
        "        kernel_size:\n",
        "            Will be deprecated in favor of `sigmas` argument. If set, the old behavior applies and `sigmas` is ignored.\n",
        "            Used to calculate sigma of gaussian blur with kernel_size * input_size.\n",
        "        sigmas:\n",
        "            Tuple of min and max value from which the std of the gaussian kernel is sampled.\n",
        "            Is ignored if `kernel_size` is set.\n",
        "        vf_prob:\n",
        "            Probability that vertical flip is applied.\n",
        "        hf_prob:\n",
        "            Probability that horizontal flip is applied.\n",
        "        rr_prob:\n",
        "            Probability that random rotation is applied.\n",
        "        rr_degrees:\n",
        "            Range of degrees to select from for random rotation. If rr_degrees is None,\n",
        "            images are rotated by 90 degrees. If rr_degrees is a (min, max) tuple,\n",
        "            images are rotated by a random angle in [min, max]. If rr_degrees is a\n",
        "            single number, images are rotated by a random angle in\n",
        "            [-rr_degrees, +rr_degrees]. All rotations are counter-clockwise.\n",
        "        normalize:\n",
        "            Dictionary with 'mean' and 'std' for torchvision.transforms.Normalize.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int = 224,\n",
        "        cj_prob: float = 0.8,\n",
        "        cj_strength: float = 0.5,\n",
        "        cj_bright: float = 0.8,\n",
        "        cj_contrast: float = 0.8,\n",
        "        cj_sat: float = 0.4,\n",
        "        cj_hue: float = 0.2,\n",
        "        min_scale: float = 0.08,\n",
        "        random_gray_scale: float = 0.2,\n",
        "        solarize_prob: float = 0.1,\n",
        "        gaussian_blur: float = 0.5,\n",
        "        kernel_size: Optional[float] = None,\n",
        "        sigmas: Tuple[float, float] = (0.1, 2),\n",
        "        vf_prob: float = 0.0,\n",
        "        hf_prob: float = 1.0,\n",
        "        rr_prob: float = 1.0,\n",
        "        rr_degrees: Union[None, float, Tuple[float, float]] = 10,\n",
        "        normalize: Union[None, dict] = IMAGENET_NORMALIZE,\n",
        "    ):\n",
        "        view_transform = VICRegViewTransform(\n",
        "            input_size=input_size,\n",
        "            cj_prob=cj_prob,\n",
        "            cj_strength=cj_strength,\n",
        "            cj_bright=cj_bright,\n",
        "            cj_contrast=cj_contrast,\n",
        "            cj_sat=cj_sat,\n",
        "            cj_hue=cj_hue,\n",
        "            min_scale=min_scale,\n",
        "            random_gray_scale=random_gray_scale,\n",
        "            solarize_prob=solarize_prob,\n",
        "            gaussian_blur=gaussian_blur,\n",
        "            kernel_size=kernel_size,\n",
        "            sigmas=sigmas,\n",
        "            vf_prob=vf_prob,\n",
        "            hf_prob=hf_prob,\n",
        "            rr_prob=rr_prob,\n",
        "            rr_degrees=rr_degrees,\n",
        "            normalize=normalize,\n",
        "        )\n",
        "        super().__init__(transforms=[view_transform, view_transform])\n",
        "\n",
        "\n",
        "class VICRegViewTransform:\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int = 224,\n",
        "        cj_prob: float = 0.8,\n",
        "        cj_strength: float = 0.5,\n",
        "        cj_bright: float = 0.8,\n",
        "        cj_contrast: float = 0.8,\n",
        "        cj_sat: float = 0.4,\n",
        "        cj_hue: float = 0.2,\n",
        "        min_scale: float = 0.08,\n",
        "        random_gray_scale: float = 0.2,\n",
        "        solarize_prob: float = 0.1,\n",
        "        gaussian_blur: float = 0.5,\n",
        "        kernel_size: Optional[float] = None,\n",
        "        sigmas: Tuple[float, float] = (0.2, 2),\n",
        "        vf_prob: float = 0.0,\n",
        "        hf_prob: float = 1.0,\n",
        "        rr_prob: float = 1.0,\n",
        "        rr_degrees: Union[None, float, Tuple[float, float]] = 20,\n",
        "        normalize: Union[None, dict] = IMAGENET_NORMALIZE,\n",
        "    ):\n",
        "        color_jitter = T.ColorJitter(\n",
        "            brightness=cj_strength * cj_bright,\n",
        "            contrast=cj_strength * cj_contrast,\n",
        "            saturation=cj_strength * cj_sat,\n",
        "            hue=cj_strength * cj_hue,\n",
        "        )\n",
        "\n",
        "        transform = [\n",
        "            T.RandomResizedCrop(size=input_size, scale=(min_scale, 1.0)),\n",
        "            # T.Resize(224),\n",
        "            random_rotation_transform(rr_prob=rr_prob, rr_degrees=rr_degrees),\n",
        "            T.RandomHorizontalFlip(p=hf_prob),\n",
        "            # T.RandomVerticalFlip(p=vf_prob),\n",
        "            T.RandomApply([color_jitter], p=cj_prob),\n",
        "            T.RandomGrayscale(p=random_gray_scale),\n",
        "            RandomSolarization(prob=solarize_prob),\n",
        "            GaussianBlur(kernel_size=kernel_size, sigmas=sigmas, prob=gaussian_blur),\n",
        "            T.ToTensor(),\n",
        "        ]\n",
        "        if normalize:\n",
        "            transform += [T.Normalize(mean=normalize[\"mean\"], std=normalize[\"std\"])]\n",
        "        self.transform = T.Compose(transform)\n",
        "\n",
        "    def __call__(self, image: Union[Tensor, Image]) -> Tensor:\n",
        "        \"\"\"\n",
        "        Applies the transforms to the input image.\n",
        "\n",
        "        Args:\n",
        "            image:\n",
        "                The input image to apply the transforms to.\n",
        "\n",
        "        Returns:\n",
        "            The transformed image.\n",
        "\n",
        "        \"\"\"\n",
        "        return self.transform(image)"
      ],
      "metadata": {
        "id": "_oNTHJdYTc22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = VICRegTransform()\n",
        "\n",
        "dataset = CreateDataset(train, 'train', transform=transform)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=8,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "mQb3_4-MSiYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=3,\n",
        "        stride=stride,\n",
        "        padding=dilation,\n",
        "        groups=groups,\n",
        "        bias=False,\n",
        "        dilation=dilation,\n",
        "    )\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    __constants__ = [\"downsample\"]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes,\n",
        "        planes,\n",
        "        stride=1,\n",
        "        downsample=None,\n",
        "        groups=1,\n",
        "        base_width=64,\n",
        "        dilation=1,\n",
        "        norm_layer=None,\n",
        "        last_activation=\"relu\",\n",
        "    ):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    __constants__ = [\"downsample\"]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes,\n",
        "        planes,\n",
        "        stride=1,\n",
        "        downsample=None,\n",
        "        groups=1,\n",
        "        base_width=64,\n",
        "        dilation=1,\n",
        "        norm_layer=None,\n",
        "        last_activation=\"relu\",\n",
        "    ):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.0)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "        if last_activation == \"relu\":\n",
        "            self.last_activation = nn.ReLU(inplace=True)\n",
        "        elif last_activation == \"none\":\n",
        "            self.last_activation = nn.Identity()\n",
        "        elif last_activation == \"sigmoid\":\n",
        "            self.last_activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.last_activation(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        block,\n",
        "        layers,\n",
        "        num_channels=3,\n",
        "        zero_init_residual=False,\n",
        "        groups=1,\n",
        "        widen=1,\n",
        "        width_per_group=64,\n",
        "        replace_stride_with_dilation=None,\n",
        "        norm_layer=None,\n",
        "        last_activation=\"relu\",\n",
        "    ):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "        # self._last_activation = last_activation\n",
        "\n",
        "        self.padding = nn.ConstantPad2d(1, 0.0)\n",
        "\n",
        "        self.inplanes = width_per_group * widen\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\n",
        "                \"replace_stride_with_dilation should be None \"\n",
        "                \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation)\n",
        "            )\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "\n",
        "        # change padding 3 -> 2 compared to original torchvision code because added a padding layer\n",
        "        num_out_filters = width_per_group * widen\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            num_channels,\n",
        "            num_out_filters,\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=2,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.bn1 = norm_layer(num_out_filters)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, num_out_filters, layers[0])\n",
        "        num_out_filters *= 2\n",
        "        self.layer2 = self._make_layer(\n",
        "            block,\n",
        "            num_out_filters,\n",
        "            layers[1],\n",
        "            stride=2,\n",
        "            dilate=replace_stride_with_dilation[0],\n",
        "        )\n",
        "        num_out_filters *= 2\n",
        "        self.layer3 = self._make_layer(\n",
        "            block,\n",
        "            num_out_filters,\n",
        "            layers[2],\n",
        "            stride=2,\n",
        "            dilate=replace_stride_with_dilation[1],\n",
        "        )\n",
        "        num_out_filters *= 2\n",
        "        self.layer4 = self._make_layer(\n",
        "            block,\n",
        "            num_out_filters,\n",
        "            layers[3],\n",
        "            stride=2,\n",
        "            dilate=replace_stride_with_dilation[2],\n",
        "            last_activation=last_activation,\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(\n",
        "        self, block, planes, blocks, stride=1, dilate=False, last_activation=\"relu\"\n",
        "    ):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(\n",
        "                self.inplanes,\n",
        "                planes,\n",
        "                stride,\n",
        "                downsample,\n",
        "                self.groups,\n",
        "                self.base_width,\n",
        "                previous_dilation,\n",
        "                norm_layer,\n",
        "                last_activation=(last_activation if blocks == 1 else \"relu\"),\n",
        "            )\n",
        "        )\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(\n",
        "                block(\n",
        "                    self.inplanes,\n",
        "                    planes,\n",
        "                    groups=self.groups,\n",
        "                    base_width=self.base_width,\n",
        "                    dilation=self.dilation,\n",
        "                    norm_layer=norm_layer,\n",
        "                    last_activation=(last_activation if i == blocks - 1 else \"relu\"),\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.padding(x)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def resnet34(**kwargs):\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs), 512\n",
        "\n",
        "\n",
        "def resnet50(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs), 2048\n",
        "\n",
        "\n",
        "def resnet101(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3], **kwargs), 2048\n",
        "\n",
        "\n",
        "def resnet50x2(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], widen=2, **kwargs), 4096\n",
        "\n",
        "\n",
        "def resnet50x4(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], widen=4, **kwargs), 8192\n",
        "\n",
        "\n",
        "def resnet50x5(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], widen=5, **kwargs), 10240\n",
        "\n",
        "\n",
        "def resnet200x2(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 24, 36, 3], widen=2, **kwargs), 4096"
      ],
      "metadata": {
        "id": "dI6hAUXwSibt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "## The projection head is the same as the Barlow Twins one\n",
        "from lightly.loss import VICRegLoss\n",
        "\n",
        "## The projection head is the same as the Barlow Twins one\n",
        "from lightly.loss.vicreg_loss import VICRegLoss\n",
        "from lightly.models.modules import BarlowTwinsProjectionHead\n",
        "# from lightly.transforms.vicreg_transform import VICRegTransform\n",
        "\n",
        "\n",
        "class VICReg(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.projection_head = BarlowTwinsProjectionHead(2048, 2048, 2048)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(x)\n",
        "        return z\n",
        "\n",
        "\n",
        "resnet = torchvision.models.resnet50()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "# backbone = resnet50()\n",
        "# backbone = backbone[0]\n",
        "# checkpoint = torch.load('/content/drive/MyDrive/vicreg/resnet50.pth')\n",
        "# backbone.load_state_dict(checkpoint)\n",
        "model = VICReg(backbone)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "wGB-d9miS06Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = VICRegLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.9, weight_decay=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 40)\n",
        "loss_val_list = []\n",
        "\n",
        "print(\"Starting Training\")\n",
        "for epoch in range(40):\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        x0, x1 = batch\n",
        "        x0 = x0.to(device)\n",
        "        x1 = x1.to(device)\n",
        "        z0 = model(x0)\n",
        "        z1 = model(x1)\n",
        "        loss = criterion(z0, z1)\n",
        "        total_loss += loss.detach()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    scheduler.step()\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "    if ((epoch+1) == 1):\n",
        "      model_save_name = f'barerandom_vicreg_chestxray_{epoch+1}_withprojectionhead.pth'\n",
        "      path = f'/content/drive/MyDrive/final_random_vicreg/{model_save_name}'\n",
        "      torch.save(model.state_dict(), path)\n",
        "\n",
        "    if ((epoch+1) % 10 == 0):\n",
        "      model_save_name = f'barerandom_vicreg_chestxray_{epoch+1}_withprojectionhead.pth'\n",
        "      path = f'/content/drive/MyDrive/final_random_vicreg/{model_save_name}'\n",
        "      torch.save(model.state_dict(), path)\n",
        "\n",
        "    if ((epoch+1) % 10 == 0):\n",
        "      model_save_name = f'barerandom_vicreg_chestxray_{epoch+1}_backbone.pth'\n",
        "      path = f'/content/drive/MyDrive/final_random_vicreg/{model_save_name}'\n",
        "      torch.save(model.backbone.state_dict(), path)\n",
        "\n",
        "    # if ((epoch+1) % 2 == 0):\n",
        "    #   torch.save(model.state_dict(), f'barerandom_vicreg_chestxray_{epoch+1}_withprojectionhead.pth')\n",
        "    #   state_dict = {'resnet50_parameters': model.backbone.state_dict()}\n",
        "    #   torch.save(state_dict, f'barerandom_vicreg_chestxray_{epoch+1}_backbonemodel.pth')\n",
        "    print(f\"epoch: {epoch+1:>02}, loss: {avg_loss:.5f}. Time taken: {((time.time()-t0)/60):.3f} mins\")\n",
        "    loss_val_list.append(avg_loss)"
      ],
      "metadata": {
        "id": "KUMcL7VwS09c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(loss_val_list)):\n",
        "  loss_val_list[i] = loss_val_list[i].item()\n",
        "np.save('/content/drive/MyDrive/final_random_vicreg/loss_barerandom_vicreg_chestxray.npy', loss_val_list)"
      ],
      "metadata": {
        "id": "1TpqkPuQS1Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "BeHxG1B0pj9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qWgTtOwop3EA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}