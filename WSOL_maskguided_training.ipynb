{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS1o4yXtkUcD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Kaggle/data.zip' -d '/content/'"
      ],
      "metadata": {
        "id": "eq6xm91fkaiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "from cv2 import imread, createCLAHE # read and equalize images\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from pandas.core.common import flatten\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "metadata": {
        "id": "1_D6awAukalG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "# pytorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# image imports\n",
        "from skimage import io, transform\n",
        "from PIL import Image\n",
        "\n",
        "# general imports\n",
        "import os\n",
        "import time\n",
        "from shutil import copyfile\n",
        "from shutil import rmtree\n",
        "\n",
        "# data science imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv"
      ],
      "metadata": {
        "id": "f3fYDIaFkanx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "import random\n",
        "np.random.seed(25)\n",
        "\n",
        "df = pd.read_csv('/content/Data_Entry_2017.csv')\n",
        "df.drop(['OriginalImage[Width', 'Height]', 'OriginalImagePixelSpacing[x', 'y]', 'Unnamed: 11'], axis=1, inplace=True)\n",
        "num_obs = len(df)\n",
        "# print('Number of observations:',num_obs)\n",
        "\n",
        "my_glob = glob('/content/images*/images/*.png')\n",
        "# print('Number of Observations: ', len(my_glob))\n",
        "\n",
        "full_img_paths = {os.path.basename(x): x for x in my_glob}\n",
        "df['full_path'] = df['Image Index'].map(full_img_paths.get)\n",
        "\n",
        "train_val_list = pd.read_csv('/content/train_val_list.txt', header=None, names = ['image_list'])\n",
        "test_list = pd.read_csv('/content/test_list.txt', header=None, names = ['image_list'])\n",
        "\n",
        "train = df[df['Image Index'].isin(train_val_list['image_list'].values)].reset_index(drop=True)\n",
        "test = df[df['Image Index'].isin(test_list['image_list'].values)].reset_index(drop=True)\n",
        "\n",
        "labels_discard = ['Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Hernia', 'Pleural_Thickening']\n",
        "for i in labels_discard:\n",
        "    train = train[~train['Finding Labels'].str.contains(i)]\n",
        "    test = test[~test['Finding Labels'].str.contains(i)]\n",
        "\n",
        "# train = pd.concat([train[~train['Finding Labels'].str.contains('No Finding')],\n",
        "#                   train[train['Finding Labels'].str.contains('No Finding')].drop_duplicates(subset=['Finding Labels', 'Patient ID', 'View Position'], keep='first')]).sort_values(by='Image Index')\n",
        "\n",
        "def one_hot_enc(df):\n",
        "    df['Finding Labels'] = df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
        "    all_labels = np.unique(list(chain(*df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
        "    for c_label in all_labels:\n",
        "        if len(c_label)>1: # leave out empty labels\n",
        "            df[c_label] = df['Finding Labels'].map(lambda finding: 1 if c_label in finding else 0)\n",
        "    return df\n",
        "\n",
        "train = one_hot_enc(train)\n",
        "test = one_hot_enc(test)\n",
        "\n",
        "train_image_paths = list(flatten(train['full_path'].values))\n",
        "test_image_paths = list(flatten(test['full_path'].values))\n",
        "\n",
        "l = np.unique(train['Patient ID'].values)\n",
        "np.random.shuffle(l)\n",
        "cut = int(np.round(((90/100)*len(l)), decimals=0))\n",
        "train_values = l[:cut]\n",
        "val_values = l[cut:]\n",
        "train_dict = dict.fromkeys(train_values, 'train')\n",
        "train_dict.update(dict.fromkeys(val_values, 'val'))\n",
        "train['fold'] = train['Patient ID'].map(train_dict.get)\n",
        "\n",
        "train = train[['full_path', 'Image Index', 'fold', 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',\n",
        "               'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax']]\n",
        "test['fold'] = 'test'\n",
        "test = test[['full_path', 'Image Index', 'fold', 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',\n",
        "             'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax']]\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "UlVNZ-qckaqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "class CreateDataset(Dataset):\n",
        "\n",
        "    def __init__(self, train, fold, transform=None):\n",
        "        self.df = train\n",
        "        self.transform = transform\n",
        "        self.df = self.df[self.df['fold'] == fold]\n",
        "\n",
        "        self.df = self.df.set_index(\"Image Index\")\n",
        "        self.PRED_LABEL = ['Atelectasis',\n",
        "                           'Cardiomegaly',\n",
        "                           'Effusion',\n",
        "                           'Infiltration',\n",
        "                           'Mass',\n",
        "                           'Nodule',\n",
        "                           'Pneumonia',\n",
        "                           'Pneumothorax']\n",
        "        RESULT_PATH = \"results/\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        image = Image.open(self.df.iloc[idx, 0])\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "        label = np.zeros(len(self.PRED_LABEL), dtype=int)\n",
        "        for i in range(0, len(self.PRED_LABEL)):\n",
        "            if(self.df[self.PRED_LABEL[i].strip()].iloc[idx].astype('int') > 0):\n",
        "                label[i] = self.df[self.PRED_LABEL[i].strip()\n",
        "                                  ].iloc[idx].astype('int')\n",
        "\n",
        "#         labels = self.df.iloc[idx, 2:]\n",
        "# #         landmarks = np.array([landmarks])\n",
        "#         labels = torch.Tensor(labels)\n",
        "# #         landmarks = landmarks.astype('float').reshape(-1, 2)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "#         sample = {'image': image, 'landmarks': landmarks}\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "XSQusbrPkatK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "N_LABELS = 8  # we are predicting 14 labels\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        # transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize(224),\n",
        "        # because resize doesn't always give 224 x 224, this ensures 224 x\n",
        "        # 224\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "}\n",
        "\n",
        "transformed_datasets = {}\n",
        "transformed_datasets['train'] = CreateDataset(train, 'train', transform=data_transforms['train'])\n",
        "transformed_datasets['val'] = CreateDataset(train, 'val', transform=data_transforms['val'])\n",
        "\n",
        "dataloaders = {}\n",
        "dataloaders['train'] = torch.utils.data.DataLoader(\n",
        "    transformed_datasets['train'],\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=8,\n",
        "    pin_memory=True)\n",
        "dataloaders['val'] = torch.utils.data.DataLoader(\n",
        "    transformed_datasets['val'],\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=8,\n",
        "    pin_memory=True)"
      ],
      "metadata": {
        "id": "PQkFvgY9kav_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ALPHA = 0.8\n",
        "# GAMMA = 2\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, alpha=0.25, gamma=2, smooth=1):\n",
        "\n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "#         inputs = F.sigmoid(inputs)\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "#         inputs = inputs.view(-1)\n",
        "#         targets = targets.view(-1)\n",
        "\n",
        "#         #first compute binary cross-entropy\n",
        "#         BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "#         BCE_EXP = torch.exp(-BCE)\n",
        "#         focal_loss = alpha * (1-BCE_EXP)**gamma * BCE\n",
        "#         focal_loss = focal_loss.mean()\n",
        "\n",
        "        BCE = torch.nn.functional.binary_cross_entropy(inputs, targets, reduction='none')\n",
        "        p_t = inputs * targets + (1 - inputs) * (1 - targets)\n",
        "        focal_loss = BCE * ((1 - p_t) ** gamma)\n",
        "\n",
        "        if alpha >= 0:\n",
        "            alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
        "            focal_loss = alpha_t * focal_loss\n",
        "\n",
        "#         reduction = 'mean'\n",
        "#         if reduction == \"mean\":\n",
        "#             focal_loss = focal_loss.mean()\n",
        "#         elif reduction == \"sum\":\n",
        "#             focal_loss = focal_loss.sum()\n",
        "\n",
        "#         print('BCE: ', BCE)\n",
        "#         print('Focal: ', focal_loss)\n",
        "\n",
        "        return focal_loss.mean()"
      ],
      "metadata": {
        "id": "J18m2-LFka8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "import os\n",
        "import torch\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(98)\n",
        "\n",
        "class AlignmentNetwork(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlignmentNetwork, self).__init__()\n",
        "\n",
        "        resnet18 = models.resnet18()\n",
        "        num_ftrs = resnet18.fc.in_features\n",
        "        resnet18.fc = nn.Linear(num_ftrs, 6)\n",
        "\n",
        "        self.model  = resnet18\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        theta = self.model(x)\n",
        "        theta = theta.view(-1, 2, 3).squeeze()\n",
        "\n",
        "        self.grid = F.affine_grid(theta, x.size())\n",
        "        x = F.grid_sample(x, self.grid)\n",
        "#         m = nn.AvgPool2d(16, stride=16)\n",
        "#         x = m(x)\n",
        "#         x = F.interpolate(x, (224,224), mode='bilinear')\n",
        "        return x"
      ],
      "metadata": {
        "id": "J4ePOHQfYtvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masks = np.load('/content/drive/MyDrive/thesis_models/final_fixed_aligned_layercam_normalized_masks.npy', allow_pickle=True)\n",
        "for i in range(1, 8):\n",
        "    masks[i] = masks[i].squeeze(0)\n",
        "for i in range(len(masks)):\n",
        "    masks[i] = masks[i].to(torch.float32)\n",
        "\n",
        "# def ptp(t, axis):\n",
        "#   return t.max(axis).values - t.min(axis).values\n",
        "\n",
        "# for i in range(len(masks)):\n",
        "#   mean, std, var = torch.mean(masks[i]), torch.std(masks[i]), torch.var(masks[i])\n",
        "#   min = torch.min\n",
        "#   masks[i]  = (masks[i]-mean)/std\n",
        "# print('-------')\n",
        "# for i in masks:\n",
        "#   mean, std, var = torch.mean(i), torch.std(i), torch.var(i)\n",
        "#   print(mean, std, var)\n",
        "\n",
        "# temp = []\n",
        "# for i in range(7):\n",
        "#     temp1 = [0., 0., 0., 0., 0., 0., 0.]\n",
        "#     temp.append(temp1)\n",
        "# masks[6] = torch.Tensor(temp)\n",
        "\n",
        "l = []\n",
        "for i in masks:\n",
        "    l.append(i)\n",
        "masks = torch.stack(l)\n",
        "\n",
        "batch_masks = []\n",
        "for i in range(32):\n",
        "    batch_masks.append(masks)\n",
        "\n",
        "batch_masks = torch.stack(batch_masks).cuda()\n",
        "batch_masks = batch_masks.to(torch.float32)"
      ],
      "metadata": {
        "id": "2gxwNY8x7V7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lung = np.load('/content/drive/MyDrive/56_lung_mask.npy', allow_pickle=True)\n",
        "\n",
        "lung = lung[0]\n",
        "lung = lung.to(torch.float32)\n",
        "\n",
        "l = []\n",
        "for i in range(256):\n",
        "    l.append(lung)\n",
        "lung = torch.stack(l).cuda()\n",
        "lung = lung.to(torch.float32)"
      ],
      "metadata": {
        "id": "tvLaXbmtMnQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "centre_lung = np.load('/content/drive/MyDrive/56_center_lung_mask.npy', allow_pickle=True)\n",
        "\n",
        "centre_lung = centre_lung[0]\n",
        "centre_lung = centre_lung.to(torch.float32)\n",
        "\n",
        "l = []\n",
        "for i in range(256):\n",
        "    l.append(centre_lung)\n",
        "centre_lung = torch.stack(l).cuda()\n",
        "centre_lung = centre_lung.to(torch.float32)\n",
        "\n",
        "# lung = centre_lung"
      ],
      "metadata": {
        "id": "QTjBbG1iMnVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the vgg16 is borrowed from the pytorch tutorial\n",
        "# the resent is used to reimplemented and the comparision experiments\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "class ResNet50(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet50, self).__init__()\n",
        "\n",
        "        resnet50_pretrained = models.densenet121()\n",
        "\n",
        "        resnet50_pretrained = nn.Sequential(*list(resnet50_pretrained.children())[:-1])\n",
        "        # resnet50_pretrained.load_state_dict(torch.load('/content/drive/MyDrive/final_random_vicreg/barerandom_vicreg_chestxray_40_backbone.pth'))\n",
        "\n",
        "        # num_ftrs = resnet50_pretrained.fc.in_features\n",
        "        # resnet50_pretrained.fc = nn.Sequential(\n",
        "        #     nn.Linear(num_ftrs, 8), nn.Sigmoid())\n",
        "\n",
        "        # resnet50_pretrained.load_state_dict(torch.load('/kaggle/input/models-for-localisation-testing/resnet50_5_chestxray8.pth'))\n",
        "\n",
        "        self.model  = list(resnet50_pretrained.children())\n",
        "\n",
        "        self.noslice1 = self.model[0]\n",
        "        self.noslice2 = self.model[1]\n",
        "        self.noslice3 = self.model[2]\n",
        "        self.noslice4 = self.model[3]\n",
        "\n",
        "        self.slice1 = self.model[4]\n",
        "        self.slice2 = self.model[5]\n",
        "        self.slice3 = self.model[6]\n",
        "        self.slice4 = self.model[7]\n",
        "\n",
        "#         self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n",
        "        self.conv = nn.Sequential(nn.Conv2d(in_channels=2048, out_channels=8, kernel_size=1))\n",
        "                                # nn.ReLU(inplace=True))\n",
        "        self.anothaone = nn.Sequential(nn.Conv2d(in_channels=8, out_channels=8, kernel_size=1))\n",
        "                                # nn.ReLU(inplace=True))\n",
        "        self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)), nn.Sigmoid())\n",
        "        # self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n",
        "        #                         nn.Flatten(),\n",
        "        #                         nn.Linear(2048, 8),\n",
        "        #                         nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x, alignment_network, batch_masks, lung_mask):\n",
        "#         x = x.to(device)\n",
        "        o = x\n",
        "#         for i in range(4):\n",
        "#             o = self.model[i](o)\n",
        "\n",
        "        # alignment_network.eval()\n",
        "        # o = alignment_network(o)\n",
        "        # aligned = o\n",
        "\n",
        "        o = self.noslice1(o)\n",
        "        o = self.noslice2(o)\n",
        "        o = self.noslice3(o)\n",
        "        o = self.noslice4(o)\n",
        "\n",
        "        # o = (o * lung_mask) + o\n",
        "\n",
        "#         anchor = cv.resize()\n",
        "#         o = o*anchor\n",
        "        o = self.slice1(o)\n",
        "        feature1 = o\n",
        "        # o = (o * lung_mask) + o\n",
        "        o = self.slice2(o)\n",
        "        feature2 = o\n",
        "        o = self.slice3(o)\n",
        "        feature3 = o\n",
        "        o = self.slice4(o)\n",
        "        feature4 = o\n",
        "        o = self.conv(o)\n",
        "        final = o\n",
        "        # if(o.shape[0] == 32):\n",
        "        #   o = (o * batch_masks) + o\n",
        "        # else:\n",
        "        #   temp = o.shape[0]\n",
        "        #   o = (o * batch_masks[:temp]) + o\n",
        "        o = self.anothaone(o)\n",
        "        final2 = o\n",
        "        o = self.fc(o)\n",
        "        final3 = o\n",
        "\n",
        "        return final3"
      ],
      "metadata": {
        "id": "9TTCvysWlPkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# model = ResNet50()\n",
        "# model = model.to(device)\n",
        "# model = model.type(torch.cuda.FloatTensor)\n",
        "\n",
        "# alignment_network = AlignmentNetwork()\n",
        "# alignment_network.load_state_dict(torch.load('/content/drive/MyDrive/fixed_pt_alignment_network_5.pth'))\n",
        "# alignment_network = alignment_network.to(device)\n",
        "# alignment_network.eval()\n",
        "# print('Aligned network loaded')"
      ],
      "metadata": {
        "id": "sBVvBJaWnuSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for data in dataloaders['train']:\n",
        "#     inputs, labels = data\n",
        "#     batch_size = inputs.shape[0]\n",
        "#     inputs = Variable(inputs.cuda())\n",
        "#     labels = Variable(labels.cuda()).float()\n",
        "#     outputs, aligned = model(inputs, alignment_network)\n",
        "#     break"
      ],
      "metadata": {
        "id": "T9oEWlwYnuf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.imshow(np.moveaxis(inputs[25].cpu().detach().numpy(), 0, 2))"
      ],
      "metadata": {
        "id": "wwwmbAlgoc6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.imshow(np.moveaxis(aligned[25].cpu().detach().numpy(), 0, 2))"
      ],
      "metadata": {
        "id": "pdN0nWuyosuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import sklearn\n",
        "import sklearn.metrics as sklm\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def make_pred_multilabel(model, alignment_network):\n",
        "    \"\"\"\n",
        "    Gives predictions for test fold and calculates AUCs using previously trained model\n",
        "\n",
        "    Args:\n",
        "        data_transforms: torchvision transforms to preprocess raw images; same as validation transforms\n",
        "        model: densenet-121 from torchvision previously fine tuned to training data\n",
        "        PATH_TO_IMAGES: path at which NIH images can be found\n",
        "    Returns:\n",
        "        pred_df: dataframe containing individual predictions and ground truth for each test image\n",
        "        auc_df: dataframe containing aggregate AUCs by train/test tuples\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    BATCH_SIZE = 32\n",
        "    NUM_WORKERS = os.cpu_count()\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            transforms.Resize(224),\n",
        "            # because resize doesn't always give 224 x 224, this ensures 224 x\n",
        "            # 224\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "    }\n",
        "    # calc preds in batches of 16, can reduce if your GPU has less RAM\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    # set model to eval mode; required for proper predictions given use of batchnorm\n",
        "    model.train(False)\n",
        "\n",
        "    # create dataloader\n",
        "    dataset = CreateDataset(test, \"test\", transform=data_transforms['test'])\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=True)\n",
        "    size = len(dataset)\n",
        "\n",
        "    # create empty dfs\n",
        "    pred_df = pd.DataFrame(columns=[\"Image Index\"])\n",
        "    true_df = pd.DataFrame(columns=[\"Image Index\"])\n",
        "\n",
        "    # iterate over dataloader\n",
        "    for i, data in enumerate(dataloader):\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "\n",
        "        true_labels = labels.cpu().data.numpy()\n",
        "        batch_size = true_labels.shape\n",
        "\n",
        "        outputs = model(inputs, alignment_network, batch_masks, lung)\n",
        "        probs = outputs.cpu().data.numpy()\n",
        "\n",
        "        # get predictions and true values for each item in batch\n",
        "        for j in range(0, batch_size[0]):\n",
        "            thisrow = {}\n",
        "            truerow = {}\n",
        "            thisrow[\"Image Index\"] = dataset.df.index[BATCH_SIZE * i + j]\n",
        "            truerow[\"Image Index\"] = dataset.df.index[BATCH_SIZE * i + j]\n",
        "\n",
        "            # iterate over each entry in prediction vector; each corresponds to\n",
        "            # individual label\n",
        "            for k in range(len(dataset.PRED_LABEL)):\n",
        "                thisrow[\"prob_\" + dataset.PRED_LABEL[k]] = probs[j, k]\n",
        "                truerow[dataset.PRED_LABEL[k]] = true_labels[j, k]\n",
        "\n",
        "            pred_df = pred_df.append(thisrow, ignore_index=True)\n",
        "            true_df = true_df.append(truerow, ignore_index=True)\n",
        "\n",
        "#         if(i % 10 == 0):\n",
        "#             print(str(i * BATCH_SIZE))\n",
        "\n",
        "    auc_df = pd.DataFrame(columns=[\"label\", \"auc\"])\n",
        "\n",
        "    # calc AUCs\n",
        "    for column in true_df:\n",
        "        if column not in [\n",
        "            'Atelectasis',\n",
        "            'Cardiomegaly',\n",
        "            'Effusion',\n",
        "            'Infiltration',\n",
        "            'Mass',\n",
        "            'Nodule',\n",
        "            'Pneumonia',\n",
        "            'Pneumothorax']:\n",
        "                    continue\n",
        "        actual = true_df[column]\n",
        "        pred = pred_df[\"prob_\" + column]\n",
        "        thisrow = {}\n",
        "        thisrow['label'] = column\n",
        "        thisrow['auc'] = np.nan\n",
        "#         try:\n",
        "#             thisrow['auc'] = sklm.roc_auc_score(\n",
        "#                 actual.as_matrix().astype(int), pred.as_matrix())\n",
        "        thisrow['auc'] = sklm.roc_auc_score(actual.astype(int), pred)\n",
        "#         except BaseException:\n",
        "#             print(\"can't calculate auc for \" + str(column))\n",
        "        auc_df = auc_df.append(thisrow, ignore_index=True)\n",
        "\n",
        "    pred_df.to_csv(\"results/preds.csv\", index=False)\n",
        "    auc_df.to_csv(\"results/aucs.csv\", index=False)\n",
        "    return pred_df, auc_df, true_df, actual, pred"
      ],
      "metadata": {
        "id": "LRXKTd0U71ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weighted BCE"
      ],
      "metadata": {
        "id": "FC_RnYWbmfQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ResNet50()\n",
        "model = model.to(device)\n",
        "model = model.type(torch.cuda.FloatTensor)\n",
        "# model.load_state_dict(torch.load('/content/drive/MyDrive/final_models/no_align_5.pth'))\n",
        "# model.load_state_dict(torch.load('/content/drive/MyDrive/final_models/no_align_5.pth'))\n",
        "# model.load_state_dict(torch.load('/content/drive/MyDrive/thesis_models/random40_vicreg_noalign_5.pth'))"
      ],
      "metadata": {
        "id": "l68pazxClTcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_pretrained = models.densenet121()\n",
        "\n",
        "resnet50_pretrained = nn.Sequential(*list(resnet50_pretrained.children())[:-1])\n",
        "resnet50_pretrained[0]"
      ],
      "metadata": {
        "id": "_-EaplqNqTBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723/21\n",
        "# https://www.fast.ai/posts/2018-07-02-adam-weight-decay.html\n",
        "# https://stackoverflow.com/questions/44452571/what-is-the-proper-way-to-weight-decay-for-adam-optimizer\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "gpu_count = torch.cuda.device_count()\n",
        "print(\"Available GPU count:\" + str(gpu_count))\n",
        "\n",
        "\n",
        "def checkpoint(model, best_loss, epoch, LR):\n",
        "    \"\"\"\n",
        "    Saves checkpoint of torchvision model during training.\n",
        "    Args:\n",
        "        model: torchvision model to be saved\n",
        "        best_loss: best val loss achieved so far in training\n",
        "        epoch: current epoch of training\n",
        "        LR: current learning rate in training\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    print('saving')\n",
        "    state = {\n",
        "        'model': model,\n",
        "        'best_loss': best_loss,\n",
        "        'epoch': epoch,\n",
        "        'rng_state': torch.get_rng_state(),\n",
        "        'LR': LR\n",
        "    }\n",
        "\n",
        "    torch.save(state, 'results/checkpoint')\n",
        "\n",
        "def get_loss(output, target, index, device):\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    num_classes = [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "    pos_weight = [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "    batch_weight = True\n",
        "\n",
        "    for num_class in num_classes:\n",
        "        assert num_class == 1\n",
        "    target = target[:, index].view(-1)\n",
        "    output = torch.transpose(output, 0, 1)\n",
        "    pos_weight = torch.from_numpy(\n",
        "        np.array(pos_weight,\n",
        "                 dtype=np.float32)).to(device).type_as(target)\n",
        "\n",
        "    if batch_weight:\n",
        "        if target.sum() == 0:\n",
        "            loss = torch.tensor(0., requires_grad=True).to(device)\n",
        "        else:\n",
        "            weight = (target.size()[0] - target.sum()) / target.sum()\n",
        "            loss = F.binary_cross_entropy_with_logits(\n",
        "                output[index].view(-1), target, pos_weight=weight)\n",
        "    else:\n",
        "        loss = F.binary_cross_entropy_with_logits(\n",
        "            output[index].view(-1), target, pos_weight=pos_weight[index])\n",
        "\n",
        "    label = torch.sigmoid(output[index].view(-1)).ge(0.5).float()\n",
        "    acc = (target == label).float().sum() / len(label)\n",
        "\n",
        "    return (loss, acc)\n",
        "\n",
        "\n",
        "def train_model(\n",
        "        model,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        LR,\n",
        "        num_epochs,\n",
        "        dataloaders,\n",
        "        dataset_sizes,\n",
        "        weight_decay):\n",
        "    \"\"\"\n",
        "    Fine tunes torchvision model to NIH CXR data.\n",
        "    Args:\n",
        "        model: torchvision model to be finetuned (densenet-121 in this case)\n",
        "        criterion: loss criterion (binary cross entropy loss, BCELoss)\n",
        "        optimizer: optimizer to use in training (SGD)\n",
        "        LR: learning rate\n",
        "        num_epochs: continue training up to this many epochs\n",
        "        dataloaders: pytorch train and val dataloaders\n",
        "        dataset_sizes: length of train and val datasets\n",
        "        weight_decay: weight decay parameter we use in SGD with momentum\n",
        "    Returns:\n",
        "        model: trained torchvision model\n",
        "        best_epoch: epoch on which best model val loss was obtained\n",
        "    \"\"\"\n",
        "    since = time.time()\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_loss = 999999\n",
        "    best_epoch = -1\n",
        "    last_train_loss = -1\n",
        "\n",
        "    auc_df_temp = 0\n",
        "    num_tasks = 8\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    alignment_network = AlignmentNetwork()\n",
        "    alignment_network.load_state_dict(torch.load('/content/drive/MyDrive/2feat_no_crop_fixed_pt_alignment_network_5.pth'))\n",
        "    # alignment_network.load_state_dict(torch.load('/content/drive/MyDrive/fixed_pt_alignment_network_5.pth'))\n",
        "    alignment_network = alignment_network.to(device)\n",
        "    alignment_network.eval()\n",
        "\n",
        "    # iterate over epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # set model to train or eval mode based on whether we are in train or\n",
        "        # val; necessary to get correct predictions given batchnorm\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train(True)\n",
        "            else:\n",
        "                model.train(False)\n",
        "\n",
        "            running_loss = 0.0\n",
        "\n",
        "            i = 0\n",
        "            total_done = 0\n",
        "            # iterate over all data in train/val dataloader:\n",
        "            for data in dataloaders[phase]:\n",
        "                i += 1\n",
        "                loss_sum = np.zeros(num_tasks)\n",
        "                acc_sum = np.zeros(num_tasks)\n",
        "                loss = 0\n",
        "                inputs, labels = data\n",
        "                batch_size = inputs.shape[0]\n",
        "                inputs = Variable(inputs.cuda())\n",
        "                labels = Variable(labels.cuda()).float()\n",
        "                outputs = model(inputs, alignment_network, batch_masks, lung)\n",
        "\n",
        "                for t in range(num_tasks):\n",
        "                    loss_t, acc_t = get_loss(outputs, labels, t, device)\n",
        "                    loss += loss_t\n",
        "                    loss_sum[t] += loss_t.item()\n",
        "                    acc_sum[t] += acc_t.item()\n",
        "                # calculate gradient and update parameters in train phase\n",
        "                optimizer.zero_grad()\n",
        "                # loss = criterion(outputs, labels)\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                running_loss += loss.data * batch_size\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "\n",
        "            if phase == 'train':\n",
        "                last_train_loss = epoch_loss\n",
        "\n",
        "            print(phase + ' epoch {}:loss {:.4f} with data size {}'.format(\n",
        "                epoch, epoch_loss, dataset_sizes[phase]))\n",
        "\n",
        "            if (epoch == (num_epochs - 1)):\n",
        "                torch.save(model.state_dict(), f'/content/drive/MyDrive/thesis_models/noalign_{epoch+6}.pth')\n",
        "\n",
        "            # decay learning rate if no val loss improvement in this epoch\n",
        "\n",
        "#             if phase == 'val' and epoch_loss > best_loss:\n",
        "#                 print(\"decay loss from \" + str(LR) + \" to \" +\n",
        "#                       str(LR / 10) + \" as not seeing improvement in val loss\")\n",
        "#                 LR = LR / 10\n",
        "#                 # create new optimizer with lower learning rate\n",
        "# #                 optimizer = optim.SGD(\n",
        "# #                     filter(\n",
        "# #                         lambda p: p.requires_grad,\n",
        "# #                         model.parameters()),\n",
        "# #                     lr=LR,\n",
        "# #                     momentum=0.9,\n",
        "# #                     weight_decay=weight_decay)\n",
        "#                 optimizer = optim.Adam(model.parameters(),lr=LR, betas=(0.9, 0.999))\n",
        "#                 print(\"created new optimizer with LR \" + str(LR))\n",
        "\n",
        "            # checkpoint model if has best val loss yet\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_epoch = epoch\n",
        "                checkpoint(model, best_loss, epoch, LR)\n",
        "\n",
        "            # log training and validation loss over each epoch\n",
        "            if phase == 'val':\n",
        "                with open(\"results/log_train\", 'a') as logfile:\n",
        "                    logwriter = csv.writer(logfile, delimiter=',')\n",
        "                    if(epoch == 1):\n",
        "                        logwriter.writerow([\"epoch\", \"train_loss\", \"val_loss\"])\n",
        "                    logwriter.writerow([epoch, last_train_loss, epoch_loss])\n",
        "\n",
        "        total_done += batch_size\n",
        "        if(total_done % (100 * batch_size) == 0):\n",
        "            print(\"completed \" + str(total_done) + \" so far in epoch\")\n",
        "\n",
        "        # break if no val loss improvement in 3 epochs\n",
        "#         if ((epoch - best_epoch) >= 3):\n",
        "#             print(\"no improvement in 3 epochs, break\")\n",
        "#             break\n",
        "\n",
        "        pred_df, auc_df, true_df, actual, pred = make_pred_multilabel(model, alignment_network)\n",
        "        if (auc_df_temp > auc_df['auc'].mean()):\n",
        "            auc_df_temp = auc_df['auc'].mean()\n",
        "            print('No increase in AUC. AUC: ', auc_df['auc'].mean())\n",
        "        if (auc_df_temp < auc_df['auc'].mean()):\n",
        "            auc_df_temp = auc_df['auc'].mean()\n",
        "            print('AUC: ', auc_df['auc'].mean())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    # load best model weights to return\n",
        "    checkpoint_best = torch.load('results/checkpoint')\n",
        "    model = checkpoint_best['model']\n",
        "\n",
        "    return model, best_epoch\n",
        "\n",
        "\n",
        "def train_cnn(LR, WEIGHT_DECAY, model):\n",
        "    \"\"\"\n",
        "    Train torchvision model to NIH data given high level hyperparameters.\n",
        "    Args:\n",
        "        PATH_TO_IMAGES: path to NIH images\n",
        "        LR: learning rate\n",
        "        WEIGHT_DECAY: weight decay parameter for SGD\n",
        "    Returns:\n",
        "        preds: torchvision model predictions on test fold with ground truth for comparison\n",
        "        aucs: AUCs for each train,test tuple\n",
        "    \"\"\"\n",
        "    NUM_EPOCHS = 5\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    try:\n",
        "        rmtree('results/')\n",
        "    except BaseException:\n",
        "        pass  # directory doesn't yet exist, no need to clear it\n",
        "    os.makedirs(\"results/\")\n",
        "\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    N_LABELS = 8  # we are predicting 14 labels\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            transforms.Resize(224),\n",
        "            # because resize doesn't always give 224 x 224, this ensures 224 x\n",
        "            # 224\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    transformed_datasets = {}\n",
        "    transformed_datasets['train'] = CreateDataset(train, 'train', transform=data_transforms['train'])\n",
        "    transformed_datasets['val'] = CreateDataset(train, 'val', transform=data_transforms['val'])\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = torch.utils.data.DataLoader(\n",
        "        transformed_datasets['train'],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=8,\n",
        "        pin_memory=True)\n",
        "    dataloaders['val'] = torch.utils.data.DataLoader(\n",
        "        transformed_datasets['val'],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=8,\n",
        "        pin_memory=True)\n",
        "\n",
        "    # please do not attempt to train without GPU as will take excessively long\n",
        "    if not use_gpu:\n",
        "        raise ValueError(\"Error, requires GPU\")\n",
        "\n",
        "    # model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
        "    # num_ftrs = model.fc.in_features\n",
        "    # model.fc = nn.Sequential(\n",
        "    #     nn.Linear(num_ftrs, N_LABELS), nn.Sigmoid())\n",
        "\n",
        "    # put model on GPU\n",
        "    model = model.cuda()\n",
        "\n",
        "#     checkpoint = torch.load('/kaggle/input/chestx-ray/resnet50_5_chestxray8.pth')\n",
        "#     model.load_state_dict(checkpoint)\n",
        "\n",
        "    # define criterion, optimizer for training\n",
        "    # criterion = nn.BCELoss()\n",
        "    criterion = FocalLoss()\n",
        "\n",
        "#     optimizer = optim.Adam(\n",
        "#         filter(\n",
        "#             lambda p: p.requires_grad,\n",
        "#             model.parameters()),\n",
        "#         lr=LR,\n",
        "#         weight_decay=WEIGHT_DECAY)\n",
        "    optimizer = optim.Adam(model.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
        "#     optimizer = optim.SGD(\n",
        "#         filter(\n",
        "#             lambda p: p.requires_grad,\n",
        "#             model.parameters()),\n",
        "#         lr=LR,\n",
        "#         momentum=0.9,\n",
        "#         weight_decay=WEIGHT_DECAY)\n",
        "    dataset_sizes = {x: len(transformed_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "    # train model\n",
        "    model, best_epoch = train_model(model, criterion, optimizer, LR, num_epochs=NUM_EPOCHS,\n",
        "                                    dataloaders=dataloaders, dataset_sizes=dataset_sizes, weight_decay=WEIGHT_DECAY)\n",
        "    print('Finished training')\n",
        "\n",
        "    # get preds and AUCs on test fold\n",
        "\n",
        "    return model, best_epoch"
      ],
      "metadata": {
        "id": "qdnxwvq1ka9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "WEIGHT_DECAY = 0.01\n",
        "LEARNING_RATE = 0.0001\n",
        "model, best_epoch = train_cnn(LEARNING_RATE, WEIGHT_DECAY, model)\n",
        "\n",
        "# noalign_10"
      ],
      "metadata": {
        "id": "GagL-3oRka_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vj1LDu45kbDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dfElNdKdkbFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Focal loss"
      ],
      "metadata": {
        "id": "Sz9FRx-pmMMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ResNet50()\n",
        "model = model.to(device)\n",
        "model = model.type(torch.cuda.FloatTensor)"
      ],
      "metadata": {
        "id": "sob91ScVkbGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723/21\n",
        "# https://www.fast.ai/posts/2018-07-02-adam-weight-decay.html\n",
        "# https://stackoverflow.com/questions/44452571/what-is-the-proper-way-to-weight-decay-for-adam-optimizer\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "gpu_count = torch.cuda.device_count()\n",
        "print(\"Available GPU count:\" + str(gpu_count))\n",
        "\n",
        "\n",
        "def checkpoint(model, best_loss, epoch, LR):\n",
        "    \"\"\"\n",
        "    Saves checkpoint of torchvision model during training.\n",
        "    Args:\n",
        "        model: torchvision model to be saved\n",
        "        best_loss: best val loss achieved so far in training\n",
        "        epoch: current epoch of training\n",
        "        LR: current learning rate in training\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    print('saving')\n",
        "    state = {\n",
        "        'model': model,\n",
        "        'best_loss': best_loss,\n",
        "        'epoch': epoch,\n",
        "        'rng_state': torch.get_rng_state(),\n",
        "        'LR': LR\n",
        "    }\n",
        "\n",
        "    torch.save(state, 'results/checkpoint')\n",
        "\n",
        "def get_loss(output, target, index, device):\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    num_classes = [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "    pos_weight = [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "    batch_weight = True\n",
        "\n",
        "    for num_class in num_classes:\n",
        "        assert num_class == 1\n",
        "    target = target[:, index].view(-1)\n",
        "    output = torch.transpose(output, 0, 1)\n",
        "    pos_weight = torch.from_numpy(\n",
        "        np.array(pos_weight,\n",
        "                 dtype=np.float32)).to(device).type_as(target)\n",
        "\n",
        "    if batch_weight:\n",
        "        if target.sum() == 0:\n",
        "            loss = torch.tensor(0., requires_grad=True).to(device)\n",
        "        else:\n",
        "            weight = (target.size()[0] - target.sum()) / target.sum()\n",
        "            loss = F.binary_cross_entropy_with_logits(\n",
        "                output[index].view(-1), target, pos_weight=weight)\n",
        "    else:\n",
        "        loss = F.binary_cross_entropy_with_logits(\n",
        "            output[index].view(-1), target, pos_weight=pos_weight[index])\n",
        "\n",
        "    label = torch.sigmoid(output[index].view(-1)).ge(0.5).float()\n",
        "    acc = (target == label).float().sum() / len(label)\n",
        "\n",
        "    return (loss, acc)\n",
        "\n",
        "\n",
        "def train_model(\n",
        "        model,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        LR,\n",
        "        num_epochs,\n",
        "        dataloaders,\n",
        "        dataset_sizes,\n",
        "        weight_decay):\n",
        "    \"\"\"\n",
        "    Fine tunes torchvision model to NIH CXR data.\n",
        "    Args:\n",
        "        model: torchvision model to be finetuned (densenet-121 in this case)\n",
        "        criterion: loss criterion (binary cross entropy loss, BCELoss)\n",
        "        optimizer: optimizer to use in training (SGD)\n",
        "        LR: learning rate\n",
        "        num_epochs: continue training up to this many epochs\n",
        "        dataloaders: pytorch train and val dataloaders\n",
        "        dataset_sizes: length of train and val datasets\n",
        "        weight_decay: weight decay parameter we use in SGD with momentum\n",
        "    Returns:\n",
        "        model: trained torchvision model\n",
        "        best_epoch: epoch on which best model val loss was obtained\n",
        "    \"\"\"\n",
        "    since = time.time()\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_loss = 999999\n",
        "    best_epoch = -1\n",
        "    last_train_loss = -1\n",
        "\n",
        "    auc_df_temp = 0\n",
        "    num_tasks = 8\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    alignment_network = AlignmentNetwork()\n",
        "    alignment_network.load_state_dict(torch.load('/content/drive/MyDrive/fixed_pt_alignment_network_5.pth'))\n",
        "    alignment_network = alignment_network.to(device)\n",
        "    alignment_network.eval()\n",
        "\n",
        "    # iterate over epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # set model to train or eval mode based on whether we are in train or\n",
        "        # val; necessary to get correct predictions given batchnorm\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train(True)\n",
        "            else:\n",
        "                model.train(False)\n",
        "\n",
        "            running_loss = 0.0\n",
        "\n",
        "            i = 0\n",
        "            total_done = 0\n",
        "            # iterate over all data in train/val dataloader:\n",
        "            for data in dataloaders[phase]:\n",
        "                i += 1\n",
        "                # loss_sum = np.zeros(num_tasks)\n",
        "                # acc_sum = np.zeros(num_tasks)\n",
        "                loss = 0\n",
        "                inputs, labels = data\n",
        "                batch_size = inputs.shape[0]\n",
        "                inputs = Variable(inputs.cuda())\n",
        "                labels = Variable(labels.cuda()).float()\n",
        "                outputs = model(inputs, alignment_network, batch_masks)\n",
        "                if (outputs.shape[0] == 32):\n",
        "                  outputs = outputs.reshape((32, 8))\n",
        "                else:\n",
        "                  outputs = outputs.reshape((outputs.shape[0], 8))\n",
        "\n",
        "                # for t in range(num_tasks):\n",
        "                #     loss_t, acc_t = get_loss(outputs, labels, t, device)\n",
        "                #     loss += loss_t\n",
        "                #     loss_sum[t] += loss_t.item()\n",
        "                #     acc_sum[t] += acc_t.item()\n",
        "                # calculate gradient and update parameters in train phase\n",
        "                optimizer.zero_grad()\n",
        "                loss = criterion(outputs, labels)\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                running_loss += loss.data * batch_size\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "\n",
        "            if phase == 'train':\n",
        "                last_train_loss = epoch_loss\n",
        "\n",
        "            print(phase + ' epoch {}:loss {:.4f} with data size {}'.format(\n",
        "                epoch, epoch_loss, dataset_sizes[phase]))\n",
        "\n",
        "            torch.save(model.state_dict(), f'/content/drive/MyDrive/random_init/focal_resnet50_{epoch+1}.pth')\n",
        "\n",
        "            # decay learning rate if no val loss improvement in this epoch\n",
        "\n",
        "#             if phase == 'val' and epoch_loss > best_loss:\n",
        "#                 print(\"decay loss from \" + str(LR) + \" to \" +\n",
        "#                       str(LR / 10) + \" as not seeing improvement in val loss\")\n",
        "#                 LR = LR / 10\n",
        "#                 # create new optimizer with lower learning rate\n",
        "# #                 optimizer = optim.SGD(\n",
        "# #                     filter(\n",
        "# #                         lambda p: p.requires_grad,\n",
        "# #                         model.parameters()),\n",
        "# #                     lr=LR,\n",
        "# #                     momentum=0.9,\n",
        "# #                     weight_decay=weight_decay)\n",
        "#                 optimizer = optim.Adam(model.parameters(),lr=LR, betas=(0.9, 0.999))\n",
        "#                 print(\"created new optimizer with LR \" + str(LR))\n",
        "\n",
        "            # checkpoint model if has best val loss yet\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_epoch = epoch\n",
        "                checkpoint(model, best_loss, epoch, LR)\n",
        "\n",
        "            # log training and validation loss over each epoch\n",
        "            if phase == 'val':\n",
        "                with open(\"results/log_train\", 'a') as logfile:\n",
        "                    logwriter = csv.writer(logfile, delimiter=',')\n",
        "                    if(epoch == 1):\n",
        "                        logwriter.writerow([\"epoch\", \"train_loss\", \"val_loss\"])\n",
        "                    logwriter.writerow([epoch, last_train_loss, epoch_loss])\n",
        "\n",
        "        total_done += batch_size\n",
        "        if(total_done % (100 * batch_size) == 0):\n",
        "            print(\"completed \" + str(total_done) + \" so far in epoch\")\n",
        "\n",
        "        # break if no val loss improvement in 3 epochs\n",
        "#         if ((epoch - best_epoch) >= 3):\n",
        "#             print(\"no improvement in 3 epochs, break\")\n",
        "#             break\n",
        "\n",
        "        pred_df, auc_df, true_df, actual, pred = make_pred_multilabel(model, alignment_network)\n",
        "        if (auc_df_temp > auc_df['auc'].mean()):\n",
        "            auc_df_temp = auc_df['auc'].mean()\n",
        "            print('No increase in AUC. AUC: ', auc_df['auc'].mean())\n",
        "        if (auc_df_temp < auc_df['auc'].mean()):\n",
        "            auc_df_temp = auc_df['auc'].mean()\n",
        "            print('AUC: ', auc_df['auc'].mean())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    # load best model weights to return\n",
        "    checkpoint_best = torch.load('results/checkpoint')\n",
        "    model = checkpoint_best['model']\n",
        "\n",
        "    return model, best_epoch\n",
        "\n",
        "\n",
        "def train_cnn(LR, WEIGHT_DECAY, model):\n",
        "    \"\"\"\n",
        "    Train torchvision model to NIH data given high level hyperparameters.\n",
        "    Args:\n",
        "        PATH_TO_IMAGES: path to NIH images\n",
        "        LR: learning rate\n",
        "        WEIGHT_DECAY: weight decay parameter for SGD\n",
        "    Returns:\n",
        "        preds: torchvision model predictions on test fold with ground truth for comparison\n",
        "        aucs: AUCs for each train,test tuple\n",
        "    \"\"\"\n",
        "    NUM_EPOCHS = 5\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    try:\n",
        "        rmtree('results/')\n",
        "    except BaseException:\n",
        "        pass  # directory doesn't yet exist, no need to clear it\n",
        "    os.makedirs(\"results/\")\n",
        "\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    N_LABELS = 8  # we are predicting 14 labels\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            transforms.Resize(224),\n",
        "            # because resize doesn't always give 224 x 224, this ensures 224 x\n",
        "            # 224\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    transformed_datasets = {}\n",
        "    transformed_datasets['train'] = CreateDataset(train, 'train', transform=data_transforms['train'])\n",
        "    transformed_datasets['val'] = CreateDataset(train, 'val', transform=data_transforms['val'])\n",
        "\n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = torch.utils.data.DataLoader(\n",
        "        transformed_datasets['train'],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=8,\n",
        "        pin_memory=True)\n",
        "    dataloaders['val'] = torch.utils.data.DataLoader(\n",
        "        transformed_datasets['val'],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=8,\n",
        "        pin_memory=True)\n",
        "\n",
        "    # please do not attempt to train without GPU as will take excessively long\n",
        "    if not use_gpu:\n",
        "        raise ValueError(\"Error, requires GPU\")\n",
        "\n",
        "    # model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
        "    # num_ftrs = model.fc.in_features\n",
        "    # model.fc = nn.Sequential(\n",
        "    #     nn.Linear(num_ftrs, N_LABELS), nn.Sigmoid())\n",
        "\n",
        "    # put model on GPU\n",
        "    model = model.cuda()\n",
        "\n",
        "#     checkpoint = torch.load('/kaggle/input/chestx-ray/resnet50_5_chestxray8.pth')\n",
        "#     model.load_state_dict(checkpoint)\n",
        "\n",
        "    # define criterion, optimizer for training\n",
        "    # criterion = nn.BCELoss()\n",
        "    criterion = FocalLoss()\n",
        "\n",
        "#     optimizer = optim.Adam(\n",
        "#         filter(\n",
        "#             lambda p: p.requires_grad,\n",
        "#             model.parameters()),\n",
        "#         lr=LR,\n",
        "#         weight_decay=WEIGHT_DECAY)\n",
        "    optimizer = optim.Adam(model.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
        "#     optimizer = optim.SGD(\n",
        "#         filter(\n",
        "#             lambda p: p.requires_grad,\n",
        "#             model.parameters()),\n",
        "#         lr=LR,\n",
        "#         momentum=0.9,\n",
        "#         weight_decay=WEIGHT_DECAY)\n",
        "    dataset_sizes = {x: len(transformed_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "    # train model\n",
        "    model, best_epoch = train_model(model, criterion, optimizer, LR, num_epochs=NUM_EPOCHS,\n",
        "                                    dataloaders=dataloaders, dataset_sizes=dataset_sizes, weight_decay=WEIGHT_DECAY)\n",
        "    print('Finished training')\n",
        "\n",
        "    # get preds and AUCs on test fold\n",
        "\n",
        "    return model, best_epoch"
      ],
      "metadata": {
        "id": "37GlqKw-kbI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "WEIGHT_DECAY = 0.01\n",
        "LEARNING_RATE = 0.0001\n",
        "model, best_epoch = train_cnn(LEARNING_RATE, WEIGHT_DECAY, model)"
      ],
      "metadata": {
        "id": "eHWt6O87mR66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mRP2AL_3yghY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}